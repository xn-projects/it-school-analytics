# -*- coding: utf-8 -*-
"""03_analyse.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vNiahMeKbkEGHImSCmIZZAsbY0hHgQPt
"""

pip install dataframe-image

# Commented out IPython magic to ensure Python compatibility.
!git clone -q https://github.com/xn-projects/it-school-analytics.git
# %cd it-school-analytics

import base64
import logging
import os
import textwrap
import time
import warnings
from io import BytesIO

import dataframe_image as dfi
import folium
import matplotlib.colors as mcolors
import matplotlib.patches as mpatches
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go
import seaborn as sns
from folium.plugins import MarkerCluster
from IPython.display import HTML, display
from matplotlib.colors import LinearSegmentedColormap
from plotly.subplots import make_subplots
from scipy.stats import kurtosis, skew

from utils import (
    DataSummary,
    cmap_cornflower,
    cmap_lavender,
    cmap_lime,
    cmap_neutral,
    cmap_tomato,
    cmap_yellow,
    compare_distributions,
    describe_cat,
    describe_num,
    get_my_palette,
    load_files,
    log_section,
    plot_change,
    save_clean_data,
    save_plot,
    save_styler_as_png,
    save_table_as_png,
    setup_logging,
    show_df,
    summarize_category,
)

warnings.filterwarnings('ignore')

setup_logging()
logging.info('Repository successfully loaded and ready')

PROJECT_ROOT = '/content/it-school-analytics'
CLEAN_DIR = os.path.join(PROJECT_ROOT, 'data', 'clean')

log_section('=== Downloading source Excel files ===')

BASE_URL = 'https://raw.githubusercontent.com/xn-projects/it-school-analytics/main/data/clean/'
FILES = ['calls_clean.xlsx', 'contacts_clean.xlsx', 'deals_clean.xlsx', 'spend_clean.xlsx']

download = load_files(BASE_URL, FILES)
logging.info(f'Downloaded {len(download)} files successfully.')

log_section('=== Reading Excel files ===')

df_calls = pd.read_excel(os.path.join(CLEAN_DIR, 'calls_clean.xlsx'),
                         dtype={'Id': str, 'CONTACTID':str}, engine='openpyxl')
df_contacts = pd.read_excel(os.path.join(CLEAN_DIR, 'contacts_clean.xlsx'),
                         dtype={'Id': str}, engine='openpyxl')
df_deals = pd.read_excel(os.path.join(CLEAN_DIR, 'deals_clean.xlsx'),
                         dtype={'Id': str, 'Contact Name':str}, engine='openpyxl')
df_spend = pd.read_excel(os.path.join(CLEAN_DIR, 'spend_clean.xlsx'),
                         engine='openpyxl')

logging.info('All files successfully loaded into DataFrames.')

log_section('=== Timeseries analysis ===')
start_time = time.time()

"""# === Timeseries analysis ==="""

df_contacts['Created Date'] = df_contacts['Created Time'].dt.date
df_contacts['Created Week'] = df_contacts['Created Time'].dt.to_period('W')
df_contacts['Created Month'] = df_contacts['Created Time'].dt.to_period('M')

df_calls['Call Date'] = df_calls['Call Start Time'].dt.date
df_calls['Call Week'] = df_calls['Call Start Time'].dt.to_period('W')
df_calls['Call Month'] = df_calls['Call Start Time'].dt.to_period('M')

df_deals['Deal Created Date'] = df_deals['Created Time'].dt.date
df_deals['Deal Created Week'] = df_deals['Created Time'].dt.to_period('W')
df_deals['Deal Created Month'] = df_deals['Created Time'].dt.to_period('M')
df_deals['Closing Day'] = df_deals['Closing Date'].dt.date
df_deals['Closing Week'] = df_deals['Closing Date'].dt.to_period('W')
df_deals['Closing Month'] = df_deals['Closing Date'].dt.to_period('M')

df_spend['Date Day'] = df_spend['Date'].dt.date
df_spend['Date Week'] = df_spend['Date'].dt.to_period('W')
df_spend['Date Month'] = df_spend['Date'].dt.to_period('M')

deals_per_week = df_deals.groupby('Deal Created Week').size().reset_index(name='Deals Count')
calls_per_week = df_calls.groupby('Call Week').size().reset_index(name='Calls Count')

time_series_week = pd.merge(
    deals_per_week,
    calls_per_week,
    left_on='Deal Created Week',
    right_on='Call Week',
    how='inner'
)

time_series_week['Date'] = time_series_week['Deal Created Week'].astype(str)

df_deals['Deal Created Week'] = pd.to_datetime(df_deals['Created Time'], errors='coerce').dt.to_period('W')
df_calls['Call Week'] = pd.to_datetime(df_calls['Call Start Time'], errors='coerce').dt.to_period('W')

deals_per_week = (
    df_deals.groupby('Deal Created Week')
    .size()
    .reset_index(name='Deals Count Week')
)

calls_per_week = (
    df_calls.groupby('Call Week')
    .size()
    .reset_index(name='Calls Count Week')
)

time_series_df_week = (
    deals_per_week
    .merge(calls_per_week, left_on='Deal Created Week', right_on='Call Week', how='inner')
)

time_series_df_week['Date Week'] = (
    time_series_df_week['Deal Created Week']
    .combine_first(time_series_df_week['Call Week'])
)
time_series_df_week['Date Week'] = time_series_df_week['Date Week'].dt.start_time
time_series_df_week.fillna(0, inplace=True)

cornflower = get_my_palette(group='Cornflower')
lime = get_my_palette(group='Lime Green')
tomato = get_my_palette(group='Tomato')

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Deals Count Week'],
    mode='lines',
    name='Deals',
    line=dict(color=cornflower[3], width=2.5),
    legendgroup='deals',
    hovertemplate='Week of %{x|%d %b %Y}<br>Deals: %{y}<extra></extra>'
))

z = np.polyfit(range(len(time_series_df_week)), time_series_df_week['Deals Count Week'], 1)
p = np.poly1d(z)
fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=p(range(len(time_series_df_week))),
    mode='lines',
    name='Deals Trend',
    line=dict(color=tomato[3], dash='dot'),
    legendgroup='deals',
    showlegend=False
))

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Calls Count Week'],
    mode='lines+markers',
    name='Calls',
    line=dict(color=lime[3], width=2.5),
    legendgroup='calls',
    hovertemplate='Week of %{x|%d %b %Y}<br>Calls: %{y}<extra></extra>'
))

z1 = np.polyfit(range(len(time_series_df_week)), time_series_df_week['Calls Count Week'], 1)
p1 = np.poly1d(z1)
fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=p1(range(len(time_series_df_week))),
    mode='lines',
    name='Calls Trend',
    line=dict(color=tomato[3], dash='dot'),
    legendgroup='calls',
    showlegend=False
))

fig.update_layout(
    title='Trends of Deals and Calls Over Time',
    title_x=0.5,
    template='plotly_white',
    width=1000, height=600,
    xaxis_title='Date',
    yaxis_title='Count',
    legend=dict(
        orientation='h',
        yanchor='bottom', y=1.02,
        xanchor='center', x=0.5,
        font=dict(size=10)
    )
)

save_plot('trends_deals_calls_week', subfolder='notebooks')
fig.show()

"""Weekly Dynamics of Calls and Deals — Summary

- **Call volume is steadily increasing**, showing a growing funnel and higher team outreach activity.
- **Deals are increasing as well**, but **more slowly** than calls — meaning efficiency is declining.
- **Conversion rate is decreasing**: more calls are being made, but fewer leads convert into deals.
- Possible causes: lower lead quality, focus on quantity over qualification, scripts not adapting, or team experience gaps.
- **Key priority**: focus on **improving conversion**, not just increasing call volume.
"""

completed_calls_week = (
    df_calls[df_calls['Outgoing Call Status'].str.lower() == 'completed']
    .groupby('Call Week')
    .size()
    .reset_index(name='Completed Calls Count Week')
)

successful_deals_week = (
    df_deals[df_deals['Stage'].str.lower() == 'payment done']
    .groupby('Deal Created Week')
    .size()
    .reset_index(name='Successful Deals Count Week')
)

time_series_df_week = (
    deals_per_week
    .merge(calls_per_week, left_on='Deal Created Week', right_on='Call Week', how='inner')
    .merge(completed_calls_week, on='Call Week', how='inner')
    .merge(successful_deals_week, left_on='Deal Created Week', right_on='Deal Created Week', how='inner')
)

time_series_df_week['Date Week'] = (
    time_series_df_week['Deal Created Week']
    .combine_first(time_series_df_week['Call Week'])
)
time_series_df_week['Date Week'] = time_series_df_week['Date Week'].dt.start_time
time_series_df_week.fillna(0, inplace=True)

cornflower = get_my_palette(group='Cornflower')
lime = get_my_palette(group='Lime Green')

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Calls Count Week'],
    mode='lines',
    name='Calls',
    line=dict(color=lime[3], width=2.5),
    yaxis='y1',
    hovertemplate='Week of %{x|%d %b %Y}<br>Calls: %{y}<extra></extra>'
))

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Completed Calls Count Week'],
    mode='lines',
    name='Completed Calls',
    line=dict(color=lime[3], width=2.5, dash='dash'),
    yaxis='y1',
    hovertemplate='Week of %{x|%d %b %Y}<br>Completed Calls: %{y}<extra></extra>'
))

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Deals Count Week'],
    mode='lines',
    name='Deals',
    line=dict(color=cornflower[3], width=2.5),
    yaxis='y2',
    hovertemplate='Week of %{x|%d %b %Y}<br>Deals: %{y}<extra></extra>'
))

fig.add_trace(go.Scatter(
    x=time_series_df_week['Date Week'],
    y=time_series_df_week['Successful Deals Count Week'],
    mode='lines',
    name='Successful Deals',
    line=dict(color=cornflower[3], width=2.5, dash='dot'),
    yaxis='y2',
    hovertemplate='Week of %{x|%d %b %Y}<br>Successful Deals: %{y}<extra></extra>'
))

fig.update_layout(
    title='Calls and Deals Over Time (Weekly)',
    title_x=0.5,
    template='plotly_white',
    width=950,
    height=450,
    hovermode='x unified',
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='center',
        x=0.5,
        font=dict(size=8)
    ),
    margin=dict(l=60, r=60, t=80, b=50),
    xaxis=dict(title='Week Start Date'),
    yaxis=dict(
        title='Calls',
        titlefont=dict(color=lime[3]),
        tickfont=dict(color=lime[3]),
        showgrid=True
    ),
    yaxis2=dict(
        title='Deals',
        overlaying='y',
        side='right',
        titlefont=dict(color=cornflower[3]),
        tickfont=dict(color=cornflower[3]),
        showgrid=False
    )
)

fig.show()

"""Weekly Performance Summary

- **Calls and Completed Calls trend closely**, showing strong call execution and stable communication flow.
- **Deals grow in line with completed calls**, indicating that outreach effectively generates interest.
- However, **Successful Deals remain low and fluctuate**, meaning many deals do not progress to closing.
- The main bottleneck is **the final conversion from Deal → Successful Deal**, not lead generation or calling activity.

**Focus Area:** Strengthen closing processes (follow-ups, objection handling, payment support) to turn created deals into completed ones.
"""

df_deals['Created Time'] = pd.to_datetime(df_deals['Created Time'], errors='coerce')
df_deals['Closing Date'] = pd.to_datetime(df_deals['Closing Date'], errors='coerce')

df_deals['Created Month'] = df_deals['Created Time'].dt.to_period('M')
created_by_month = df_deals.groupby('Created Month').size()

deals_filtered = df_deals[
    df_deals['Closing Date'].notna()
]
deals_filtered['Deal Month'] = deals_filtered['Closing Date'].dt.to_period('M')
closed_by_month = deals_filtered.groupby('Deal Month').size()

successful_by_month = (
    df_deals[df_deals['Stage'].str.lower() == 'payment done']
    .groupby(df_deals['Created Time'].dt.to_period('M'))
    .size()
)

summary = pd.DataFrame({
    'Created': created_by_month,
    'Closed': closed_by_month,
    'Successful': successful_by_month
}).fillna(0).astype(int)

summary = summary[summary['Created'] > 0].copy()
summary['Closed Percentage'] = (summary['Closed'] / summary['Created'] * 100).round(1)
summary['Successful Percentage'] = (summary['Successful'] / summary['Created'] * 100).round(1)

lavender = get_my_palette(group='Lavender')
cornflower = get_my_palette(group='Cornflower')
tomato = get_my_palette(group='Tomato')

my_palette = {
    'Created': lavender[3],
    'Closed':  cornflower[3]
}
line_color = tomato[3]

summary_reset = summary.reset_index().rename(columns={'index': 'Month'})
summary_melted = summary_reset.melt(
    id_vars=['Month', 'Successful Percentage'],
    value_vars=['Created', 'Closed'],
    var_name='Type',
    value_name='Count'
)

sns.set_theme(style='whitegrid')
fig, ax1 = plt.subplots(figsize=(10, 6))

sns.barplot(
    data=summary_melted,
    x='Month', y='Count',
    hue='Type', palette=my_palette, ax=ax1
)

for p in ax1.patches:
    h = p.get_height()
    if h > 0:
        ax1.annotate(
            f'{int(h)}',
            (p.get_x() + p.get_width()/2, h + (ax1.get_ylim()[1] * 0.01)),
            ha='center', va='bottom', color='black', fontsize=8
        )

ax2 = ax1.twinx()
ax2.grid(False)

line = ax2.plot(
    summary_reset['Month'].astype(str),
    summary_reset['Successful Percentage'],
    color=line_color, marker='o', linewidth=2.5, label='Successful %'
)[0]

for x, y in zip(summary_reset['Month'].astype(str), summary_reset['Successful Percentage']):
    ax2.text(
        x, y - (ax2.get_ylim()[1] * 0.02),
        f'{y:.1f}%',
        fontsize=8,
        ha='center', va='top'
    )

handles1, labels1 = ax1.get_legend_handles_labels()
handles = handles1 + [line]
labels = labels1 + ['Successful %']
ax1.legend(handles=handles, labels=labels, title='', loc='upper left', frameon=False, fontsize=8)

ax1.set_title('Created vs Closed Deals by Month', fontsize=14, pad=12)
ax1.set_xlabel('Month', fontsize=8)
ax1.set_ylabel('Number of Deals', fontsize=8)
ax2.set_ylabel('Successful Percentage (%)', fontsize=8)

ax1.tick_params(axis='both', labelsize=8)
ax2.tick_params(axis='y', labelsize=8)
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

"""This chart compares how many deals were **created** vs **successfully closed** each month and shows the **success rate (%)** on top.  
We see strong growth in created deals from late 2023 to early 2024, especially a peak in **April 2024**, where deal creation surged dramatically.  
However, the **closing rate does not scale proportionally** — the success percentage actually **declines** during the periods of rapid growth (April drops to only **2.8%**).  
The highest success rates (around **6–7%**) appear earlier, when the number of deals created was more moderate, suggesting **capacity limits or pipeline pressure**.  
This indicates that **volume increased faster than the team/system could convert**, pointing to a need for **process optimization or resource balancing** to support higher lead flows.
"""

time_series_df_week['Conversion Rate'] = (
    time_series_df_week['Deals Count Week'] / time_series_df_week['Calls Count Week']
)

time_series_df_week['Conversion Rate'].replace([np.inf, -np.inf], np.nan, inplace=True)
time_series_df_week['Conversion Rate'].fillna(0, inplace=True)

time_series_df_week['Conversion Rate %'] = (time_series_df_week['Conversion Rate'] * 100).round(1)

df_deals['Deal Created Month'] = (
    pd.to_datetime(df_deals['Created Time'], errors='coerce')
    .dt.to_period('M')
    .dt.to_timestamp()
)
df_calls['Call Month'] = (
    pd.to_datetime(df_calls['Call Start Time'], errors='coerce')
    .dt.to_period('M')
    .dt.to_timestamp()
)

deals_month = df_deals.groupby('Deal Created Month', as_index=False).agg(
    Deals_Count=('Id', 'count')
)
calls_month = df_calls.groupby('Call Month', as_index=False).agg(
    Calls_Count=('Id', 'count')
)

merged = pd.merge(
    deals_month, calls_month,
    left_on='Deal Created Month', right_on='Call Month', how='inner'
)

merged['Month'] = merged['Deal Created Month'].combine_first(merged['Call Month'])
merged = merged[['Month', 'Calls_Count', 'Deals_Count']]

merged[['Calls_Count', 'Deals_Count']] = merged[['Calls_Count', 'Deals_Count']].fillna(0)

merged = merged.dropna(subset=['Month']).sort_values('Month')

merged['Conversion_Rate'] = np.where(
    merged['Calls_Count'] > 0,
    merged['Deals_Count'] / merged['Calls_Count'],
    0
)
merged['Conversion_Rate_%'] = (merged['Conversion_Rate'] * 100).round(1)

colors = get_my_palette(as_dict=True)
cornflower = colors["Cornflower"][3]
lavender = colors["Lavender"][3]
tomato = colors["Tomato"][3]

fig = go.Figure()

fig.add_trace(go.Bar(
    x=merged['Month'], y=merged['Calls_Count'],
    name='Calls', marker_color=lavender, opacity=0.6
))
fig.add_trace(go.Bar(
    x=merged['Month'], y=merged['Deals_Count'],
    name='Deals', marker_color=cornflower, opacity=0.8
))
fig.add_trace(go.Scatter(
    x=merged['Month'], y=merged['Conversion_Rate_%'],
    name='Conversion %', yaxis='y2',
    mode='lines+markers+text',
    line=dict(color=tomato, width=2.5, dash='dot'),
    marker=dict(size=7, color=tomato),
    text=[f"{y:.1f}%" for y in merged['Conversion_Rate_%']],
    textposition='top center'
))

fig.update_layout(
    title='Calls vs Deals vs Conversion (Monthly)',
    title_x=0.5,
    template='plotly_white',
    barmode='group',
    width=1100,
    height=550,
    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
    margin=dict(l=60, r=80, t=70, b=60),
    xaxis=dict(title='Month', tickformat='%b %Y', tickangle=-45, showgrid=True),
    yaxis=dict(title='Number of Calls / Deals', showgrid=True),
    yaxis2=dict(title='Conversion (%)', overlaying='y', side='right', showgrid=False)
)

fig.show()

"""**Monthly Calls → Deals → Conversion Analysis**

The volume of calls and deals generally increases over time, peaking around **March–April 2024,** which indicates a strong push in outreach and deal generation. However, despite higher activity levels, **conversion rates fluctuate**, showing that more calls do not automatically translate into proportionally more deals.
A key insight is that **July 2023 had a very high conversion rate (~32%)**  even with low call volume, meaning early leads were more qualified or easier to convert. By contrast, the drop to ~15.5% in May 2024 suggests either lower lead quality, capacity strain, or process inefficiencies as volumes increased.
The improvement back to **18% in June 2024** shows early recovery, but sustaining strong performance will require focusing not just on volume, but **lead qualification consistency and conversion efficiency.**

**Insight:** The team is scaling activity successfully, but to unlock maximum revenue, the next growth lever is conversion optimization, not further call volume increases.
"""

df_deals['Duration'] = (df_deals['Closing Date'] - df_deals['Created Time']).dt.days

heatmap_mean = df_deals.groupby(['Deal Created Month', 'Closing Month'])['Duration'].mean().unstack()
heatmap_count = df_deals.groupby(['Deal Created Month', 'Closing Month'])['Duration'].count().unstack()
heatmap_count_filled = heatmap_count.fillna(0).astype(int)

heatmap_mean.index = heatmap_mean.index.strftime('%b %Y')
heatmap_mean.columns = heatmap_mean.columns.strftime('%b %Y')

heatmap_count_filled.index = heatmap_count_filled.index.strftime('%b %Y')
heatmap_count_filled.columns = heatmap_count_filled.columns.strftime('%b %Y')

colors = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')
lime = get_my_palette(group='Lime Green')
cmap_custom = LinearSegmentedColormap.from_list('lavender_map', colors)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

ax1 = sns.heatmap(
    heatmap_mean,
    annot=True,
    fmt='.1f',
    cmap=cmap_custom,
    annot_kws={'size': 8},
    cbar_kws={'label': 'Average Duration (days)', 'shrink': 0.8, 'aspect': 25, 'pad': 0.02},
    ax=axes[0]
)

for i in range(len(heatmap_mean)):
    ax1.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor=lime[-1], lw=1.2))

for y, x in zip(*np.where(heatmap_mean > 100)):
    ax1.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor=tomato[-1], lw=1.2))

ax1.set_title('Average Deal Duration', fontsize=11, weight='bold', pad=12)
ax1.set_xlabel('Closing Month', fontsize=8)
ax1.set_ylabel('Creation Month', fontsize=8)
ax1.tick_params(axis='x', rotation=45, labelsize=8)
ax1.tick_params(axis='y', labelsize=8)
ax1.collections[0].colorbar.ax.tick_params(labelsize=8)
ax1.collections[0].colorbar.ax.set_ylabel('Average Duration (days)', fontsize=8)
ax1.grid(False)

ax2 = sns.heatmap(
    heatmap_mean,
    annot=heatmap_count_filled,
    fmt='d',
    cmap=cmap_custom,
    annot_kws={'size': 8, 'color': 'black'},
    cbar_kws={'label': 'Average Duration (days)', 'shrink': 0.8, 'aspect': 25, 'pad': 0.02},
    ax=axes[1]
)

for i in range(len(heatmap_mean)):
    ax2.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor=lime[-1], lw=1.2))

for y, x in zip(*np.where(heatmap_mean > 100)):
    ax2.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor=tomato[-1], lw=1.2))

ax2.set_title('Deal Count per Month (Color = Duration)', fontsize=11, weight='bold', pad=12)
ax2.set_xlabel('Closing Month', fontsize=8)
ax2.set_ylabel('')
ax2.tick_params(axis='x', rotation=45, labelsize=8)
ax2.tick_params(axis='y', labelsize=8)
ax2.collections[0].colorbar.ax.tick_params(labelsize=8)
ax2.collections[0].colorbar.ax.set_ylabel('Average Duration (days)', fontsize=8)
ax2.grid(False)

plt.tight_layout()

save_plot('deals_day_duration', subfolder='notebooks')
plt.show()

"""Most deals are closed within **1–3 months** after creation, which reflects a standard sales cycle.

There are periods with **abnormally long closing times (200–300 days, marked in red)** — mainly for deals created in **summer–autumn 2023**.  
This may indicate extended customer decision-making or issues with account follow-up and support.

In **2024**, the average deal duration becomes noticeably **shorter**, suggesting improved processing speed and workflow efficiency.

**Conclusion:**  
The deal cycle is gradually **accelerating**, but the **autumn 2023 period** shows signs of delays — likely tied to waiting for payment or stalled client communication.
"""

df_success = df_deals[df_deals['Stage'].str.lower() == 'payment done'].copy()

df_success['Duration'] = (df_success['Closing Date'] - df_success['Created Time']).dt.days

heatmap_mean = df_success.groupby(['Deal Created Month', 'Closing Month'])['Duration'].mean().unstack()

heatmap_count = df_success.groupby(['Deal Created Month', 'Closing Month'])['Duration'].count().unstack()
heatmap_count_filled = heatmap_count.fillna(0).astype(int)

heatmap_mean.index = heatmap_mean.index.strftime('%b %Y')
heatmap_mean.columns = heatmap_mean.columns.strftime('%b %Y')

heatmap_count_filled.index = heatmap_count_filled.index.strftime('%b %Y')
heatmap_count_filled.columns = heatmap_count_filled.columns.strftime('%b %Y')

colors = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')
lime = get_my_palette(group='Lime Green')
cmap_custom = LinearSegmentedColormap.from_list('lavender_map', colors)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

ax1 = sns.heatmap(
    heatmap_mean,
    annot=True,
    fmt='.1f',
    cmap=cmap_custom,
    annot_kws={'size': 8},
    cbar_kws={'label': 'Average Duration (days)', 'shrink': 0.8, 'aspect': 25, 'pad': 0.02},
    ax=axes[0]
)

for i in range(len(heatmap_mean)):
    ax1.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor=lime[-1], lw=1.2))

for y, x in zip(*np.where(heatmap_mean > 100)):
    ax1.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor=tomato[-1], lw=1.2))

ax1.set_title('Average Duration of Successful Deals', fontsize=11, weight='bold', pad=12)
ax1.set_xlabel('Closing Month', fontsize=8)
ax1.set_ylabel('Creation Month', fontsize=8)
ax1.tick_params(axis='x', rotation=45, labelsize=8)
ax1.tick_params(axis='y', labelsize=8)
ax1.collections[0].colorbar.ax.tick_params(labelsize=8)
ax1.collections[0].colorbar.ax.set_ylabel('Average Duration (days)', fontsize=8)
ax1.grid(False)

ax2 = sns.heatmap(
    heatmap_mean,
    annot=heatmap_count_filled,
    fmt='d',
    cmap=cmap_custom,
    annot_kws={'size': 8, 'color': 'black'},
    cbar_kws={'label': 'Average Duration (days)', 'shrink': 0.8, 'aspect': 25, 'pad': 0.02},
    ax=axes[1]
)

for i in range(len(heatmap_mean)):
    ax2.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor=lime[-1], lw=1.2))

for y, x in zip(*np.where(heatmap_mean > 100)):
    ax2.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor=tomato[-1], lw=1.2))

ax2.set_title('Successful Deals Count per Month (Color = Duration)', fontsize=11, weight='bold', pad=12)
ax2.set_xlabel('Closing Month', fontsize=8)
ax2.set_ylabel('')
ax2.tick_params(axis='x', rotation=45, labelsize=8)
ax2.tick_params(axis='y', labelsize=8)
ax2.collections[0].colorbar.ax.tick_params(labelsize=8)
ax2.collections[0].colorbar.ax.set_ylabel('Average Duration (days)', fontsize=8)
ax2.grid(False)

plt.tight_layout()

save_plot('successful_deals_day_duration', subfolder='notebooks')
plt.show()

"""In late 2023 – early 2024, deal durations increased significantly. Many deals took **150–300+** days to close. This indicates slower decision-making and a heavier pipeline.

Starting from spring 2024, deals began closing much faster (often **5–30 days**), while the number of successful deals remained stable.
→ This suggests higher lead quality and more efficient sales processes.

Peak successful closures occurred in February–April 2024, even though deal durations were long.
→ The team managed to close a large backlog during this period.

**Key Insight**

The funnel became more efficient in 2024:
Lead qualification improved, follow-ups became faster, and decisions were made sooner — resulting in shorter cycles with the same or higher close volume.
"""

df_deals['Created Time'] = pd.to_datetime(df_deals['Created Time'], errors='coerce')
df_deals['Closing Date'] = pd.to_datetime(df_deals['Closing Date'], errors='coerce')

deals_closed = df_deals[df_deals['Closing Date'].notna()].copy()

deals_closed['Duration Days'] = (deals_closed['Closing Date'] - deals_closed['Created Time']).dt.days

deals_closed['Closing Weekday'] = deals_closed['Closing Date'].dt.day_name()

weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

lavender = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')

weekday_deals = (
    deals_closed.groupby('Closing Weekday')['Id']
    .count()
    .reindex(weekday_order)
    .reset_index(name='Number of Deals')
)

weekday_success = (
    deals_closed[deals_closed['Stage'].str.lower() == 'payment done']
    .groupby('Closing Weekday')['Id']
    .count()
    .reindex(weekday_order)
    .reset_index(name='Successful Deals')
)

weekday_summary = pd.merge(weekday_deals, weekday_success, on='Closing Weekday', how='left').fillna(0)

plt.figure(figsize=(8, 4), dpi=100)

ax = sns.barplot(
    data=weekday_summary,
    x='Closing Weekday',
    y='Number of Deals',
    order=weekday_order,
    color=lavender[3],
    alpha=0.8,
    label='All Deals'
)

ax = sns.barplot(
    data=weekday_summary,
    x='Closing Weekday',
    y='Successful Deals',
    order=weekday_order,
    color=tomato[2],
    alpha=0.9,
    label='Successful Deals'
)

for container in ax.containers:
    ax.bar_label(container, fmt='%.0f', fontsize=7, padding=1)

plt.title('Deals by Day of the Week (All vs Successful)', fontsize=14, pad=12)
plt.xlabel('')
plt.ylabel('Number of Deals', fontsize=8)
plt.xticks(rotation=30, fontsize=8)
plt.yticks(fontsize=8)
plt.grid(axis='y', linestyle=':', alpha=0.4)
sns.despine()
plt.legend(fontsize=8, frameon=False, loc='upper right')
plt.tight_layout()

save_plot('deals_by_weekday_successful', subfolder='notebooks')
plt.show()

"""The highest number of deals occurs **on Tuesday and Wednesday**, followed by a gradual decline toward the weekend.
On Saturday and Sunday, activity is minimal.
This pattern is typical for the B2C segment, where customer engagement is highest during weekdays.

**Conclusion:**
Manager productivity is strongest at the beginning of the week. It is recommended to focus key activities and outreach efforts on these days.
"""

lime = get_my_palette(group='Lime Green')[2]
cornflower = get_my_palette(group='Cornflower')[3]

deals_closed['Is Successful'] = deals_closed['Stage'].str.lower().eq('payment done')
deals_closed['Duration Days'] = (deals_closed['Closing Date'] - deals_closed['Created Time']).dt.days

deals_closed['Duration Log'] = np.log1p(deals_closed['Duration Days'])

fig, axes = plt.subplots(1, 2, figsize=(10, 4), dpi=100)

sns.violinplot(
    data=deals_closed,
    x='Is Successful',
    y='Duration Days',
    palette=[lime, cornflower],
    inner='quartile',
    linewidth=1,
    ax=axes[0]
)
axes[0].set_title('Before Log Transformation', fontsize=12)
axes[0].set_xlabel('Successful Deal', fontsize=8)
axes[0].set_ylabel('Duration (days)', fontsize=8)
axes[0].set_xticklabels(['No', 'Yes'], fontsize=8)
axes[0].tick_params(axis='y', labelsize=8)

sns.violinplot(
    data=deals_closed,
    x='Is Successful',
    y='Duration Log',
    palette=[lime, cornflower],
    inner='quartile',
    linewidth=1,
    ax=axes[1]
)
axes[1].set_title('After Log Transformation', fontsize=12)
axes[1].set_xlabel('Successful Deal', fontsize=8)
axes[1].set_ylabel('Log(Duration)', fontsize=8)
axes[1].set_xticklabels(['No', 'Yes'], fontsize=8)
axes[1].tick_params(axis='y', labelsize=8)

plt.suptitle('Deal Duration Distribution by Success', fontsize=14, y=1.02)
sns.despine()
plt.tight_layout()

save_plot('deal_duration_distribution', subfolder='notebooks')

plt.show()

"""Successful deals (Yes) tend to take longer on average — likely because customers go through the full decision and payment cycle.

Unsuccessful deals (No) are more often closed quickly (within 0–30 days), which may indicate an early-stage refusal.

After log transformation, the distribution becomes more symmetrical, confirming the high variability in deal duration.

**Conclusion:**
Deal duration is an important predictor of success. Shorter deals are more likely to fail before payment, while successful ones require more time and consistent follow-up.
"""

duration_stats = (
    deals_closed.groupby('Stage')['Duration Days']
    .agg(['count', 'mean', 'median', 'min', 'max'])
    .sort_values('mean')
    .round(2)
)

display(duration_stats)

"""The longest average duration is seen at the **Call Delayed (23 days) and Payment Done (32 days)** stages.

The Lost stage occurs most frequently **(11,611 cases)** with an average duration of 15 days, indicating that many clients are being lost early in the process.

Some stages (e.g., Waiting for Payment) show a very wide duration range — **up to 105 days** — suggesting inefficient waiting periods.

**Conclusion:**
The main time delays occur during waiting for payment and postponed call stages. Optimizing these steps could significantly accelerate the overall deal cycle.
"""

df_deals['AOV_i'] = ((df_deals['Initial Amount Paid'] +
                        (df_deals['Offer Total Amount'] -
                         df_deals['Initial Amount Paid']) /
                        (df_deals['Course duration'] - 1) *
                        (df_deals['Months of study'] - 1)) /
                        df_deals['Months of study'])

df_deals['R_i'] = df_deals['AOV_i'] * df_deals['Months of study']

deals_weekly = df_deals.groupby(pd.Grouper(key='Created Time', freq='W')).size().reset_index(name='Total Deals Count')
calls_weekly = df_calls.groupby(pd.Grouper(key='Call Start Time', freq='W')).size().reset_index(name='Calls Count')
contacts_weekly = df_contacts.groupby(pd.Grouper(key='Created Time', freq='W')).size().reset_index(name='Сontacts Count')

payment_deals = df_deals[df_deals['Stage'] == "Payment Done"]
successful_per_week_count = payment_deals.groupby(pd.Grouper(key='Created Time', freq='W')).size().reset_index(name='Successful Deals Count')

spend_weekly = df_spend.groupby(pd.Grouper(key='Date', freq='W')).agg(Spend = ('Spend', 'sum'),
                                                                           Spend_avg = ('Spend', 'mean'),
                                                                           Impressions = ('Impressions', 'sum'),
                                                                           Clicks = ('Clicks', 'sum')
                                                                           ).reset_index()

successful_per_week_sum = payment_deals.groupby(pd.Grouper(key='Created Time', freq='W'))['R_i'] \
                                        .sum().reset_index(name='Real Amount')

deals_weekly.rename(columns={'Created Time': 'Date'}, inplace=True)
calls_weekly.rename(columns={'Call Start Time': 'Date'}, inplace=True)
contacts_weekly.rename(columns={'Created Time': 'Date'}, inplace=True)

weekly_time_series_df = (
    deals_weekly
    .merge(calls_weekly, on='Date', how='outer')
    .merge(contacts_weekly, on='Date', how='outer')
    .merge(spend_weekly, on='Date', how='outer')
    .fillna(0)
    .sort_values('Date'))

dataframes = {
    'deals_weekly': deals_weekly,
    'calls_weekly': calls_weekly,
    'contacts_weekly': contacts_weekly,
    'successful_per_week_count': successful_per_week_count,
    'spend_weekly': spend_weekly,
    'successful_per_week_sum': successful_per_week_sum
}

for name, df in dataframes.items():
    if not df.index.is_numeric():
        df.reset_index(inplace=True)

    for col in ['Date', 'Created Time', 'Week', 'index']:
        if col in df.columns:
            df.rename(columns={col: 'Date'}, inplace=True)
            break

    if 'Date' not in df.columns:
        df['Date'] = df.index

    df.set_index('Date', inplace=True)

time_series_data = (
    dataframes['deals_weekly']
    .join(dataframes['calls_weekly'], how='outer')
    .join(dataframes['contacts_weekly'], how='outer')
    .join(dataframes['successful_per_week_count'], how='outer')
    .join(dataframes['spend_weekly'], how='outer')
    .join(dataframes['successful_per_week_sum'], how='outer')
    .dropna()
    .sort_index()
)

time_series_data.index.name = 'Week'
time_series_data = time_series_data.reset_index()
time_series_data['Week'] = pd.to_datetime(time_series_data['Week'], errors='coerce')

display(time_series_data.head(3))

time_series_data['Week'] = pd.to_datetime(time_series_data['Week']).dt.date

colors = get_my_palette(as_dict=True)
lavender = colors['Lavender'][-1]
lime = colors['Lime Green'][4]
cornflower = colors['Cornflower'][-1]
tomato = colors['Tomato'][-1]

fig3_1_2 = go.Figure()

fig3_1_2.add_trace(go.Bar(
    x=time_series_data['Week'],
    y=time_series_data['Impressions'],
    name='Impressions',
    hovertemplate='Week: %{x}<br>Impressions: %{y:,}<extra></extra>',
    marker=dict(color=lavender, line=dict(color='black', width=0.5), opacity=0.35),
    yaxis='y2'
))

fig3_1_2.add_trace(go.Scatter(
    x=time_series_data['Week'],
    y=time_series_data['Clicks'],
    mode='lines',
    name='Clicks',
    line=dict(color=lime, width=3),
    hovertemplate='Week: %{x}<br>Clicks: %{y:,}<extra></extra>'
))

fig3_1_2.add_trace(go.Scatter(
    x=time_series_data['Week'],
    y=time_series_data['Calls Count'],
    mode='lines',
    name='Calls Count',
    line=dict(color=cornflower, width=3),
    hovertemplate='Week: %{x}<br>Calls: %{y:,}<extra></extra>'
))

fig3_1_2.add_trace(go.Scatter(
    x=time_series_data['Week'],
    y=time_series_data['Total Deals Count'],
    mode='lines',
    name='Deals Count',
    line=dict(color=tomato, width=3.2),
    hovertemplate='Week: %{x}<br>Deals: %{y:,}<extra></extra>'
))

fig3_1_2.update_layout(
    title=dict(
        text='Dynamics of Impressions, Clicks, Calls and Deals by Week',
        x=0.5,
        font=dict(family='Georgia', size=20, color='black')
    ),
    xaxis=dict(
        title='Week',
        tickangle=40,
        showgrid=False,
        titlefont=dict(size=13, color='black'),
        tickfont=dict(size=10)
    ),
    yaxis=dict(
        title='Calls / Deals / Clicks',
        showgrid=False,
        titlefont=dict(size=13, color='black')
    ),
    yaxis2=dict(
        title='Impressions',
        overlaying='y',
        side='right',
        showgrid=False,
        titlefont=dict(size=13, color='black')
    ),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.05,
        xanchor='center',
        x=0.5,
        font=dict(family='Georgia', size=11, color='black')
    ),
    hovermode='x unified',
    template='plotly_white',
    width=950,
    height=480,
    margin=dict(l=60, r=80, t=80, b=60)
)

fig3_1_2.show()

"""**Weekly Dynamics: Impressions → Clicks → Calls → Deals**

The chart shows a clear funnel behavior: when impressions increase, clicks and call volumes typically rise with a short delay, and deals follow after calls.  
There are two strong seasonal peaks — early autumn (Sep–Oct) and late spring (Apr–May), where traffic and interactions intensify across all stages.  
However, the conversion from calls to deals remains relatively stable and does **not grow proportionally** with the increase in impressions and clicks — this points to a *capacity or efficiency ceiling* in the sales process.  
Periods with high clicks but comparatively lower calls (e.g., mid-winter) suggest lost opportunities due to insufficient contact follow-up or workload imbalance.  

**Insight:** Traffic growth alone doesn’t automatically increase closed deals — the **bottleneck lies in converting calls into successful conversations**. Strengthening call handling quality and follow-up processes will yield a higher return from existing traffic levels.
"""

corr_cols = [
    'Impressions', 'Clicks', 'Spend', 'Сontacts Count',
    'Calls Count', 'Total Deals Count', 'Successful Deals Count',
    'Real Amount'
]

corr_matrix = time_series_data[corr_cols].corr().round(2)

colors = get_my_palette(as_dict=True)

fig = go.Figure()

mask = np.tril(np.ones_like(corr_matrix, dtype=bool))
masked_corr = corr_matrix.where(mask)

z = masked_corr.values[::-1]
text = [[f'<b>{v:.2f}</b>' if not np.isnan(v) else '' for v in row] for row in z]

fig.add_trace(go.Heatmap(
    z=z,
    x=corr_cols,
    y=corr_cols[::-1],
    text=text,
    texttemplate='%{text}',
    textfont={'size': 10},
    zmin=0.3, zmax=1.0,
    colorscale=[
        [0, colors['Lavender'][0]],
        [1, colors['Cornflower'][-1]]
    ],
    colorbar=dict(
        title='Correlation',
        titleside='right',
        tickvals=[0.3, 0.5, 0.7, 0.9, 1.0],
        ticktext=['0.3', '0.5', '0.7', '0.9', '1.0'],
        titlefont=dict(size=13),
        tickfont=dict(size=11),
        len=0.75,
        thickness=18
    )
))

n = len(corr_matrix)
for i in range(n):
    for j in range(n):
        val = corr_matrix.iloc[i, j]
        if np.isnan(val) or i < j:
            continue

        color = None
        if val >= 0.8:
            color = lime
        elif val <= 0.2:
            color = tomato

        if color:
            y_rev = n - 1 - i
            fig.add_shape(
                type='rect',
                x0=j - 0.5, x1=j + 0.5,
                y0=y_rev - 0.5, y1=y_rev + 0.5,
                xref='x', yref='y',
                line=dict(color=color, width=2),
                fillcolor='rgba(0,0,0,0)'
            )

fig.update_layout(
    title=dict(
        text='Correlation Heatmap',
        x=0.5,
        font=dict(family='Georgia', size=20, color='black')
    ),
    width=750,
    height=600,
    template='plotly_white',
    margin=dict(l=80, r=80, t=80, b=80)
)

fig.update_xaxes(tickangle=-45, tickfont=dict(size=11))
fig.update_yaxes(tickfont=dict(size=11))

fig.show()

"""There are strong positive correlations between **Impressions → Clicks → Calls → Deals**, confirming that the marketing funnel is functioning effectively.

A strong relationship is also observed between **Successful Deals** and **Real Amount**, which is expected.

However, the **moderate correlations** between **Spend** and **Successful Deals** indicate that increasing the advertising budget does **not always** lead to more successful conversions.

**Conclusion:**  
The marketing → calls → deals chain is working cohesively, but the **ROI of advertising spend requires deeper evaluation**.
"""

df_deals['Duration Days'] = (df_deals['Closing Date'] - df_deals['Created Time']).dt.days
df_deals_valid = df_deals[df_deals['Duration Days'].between(0, df_deals['Duration Days'].quantile(0.99))]

monthly_duration = (
    df_deals_valid
    .groupby(df_deals_valid['Closing Date'].dt.to_period('M'))
    .agg(Deals=('Id', 'count'),
         AvgDuration=('Duration Days', 'mean'))
    .reset_index()
)
monthly_duration['Month'] = monthly_duration['Closing Date'].dt.to_timestamp()

colors = get_my_palette(as_dict=True)

fig_duration = make_subplots(specs=[[{'secondary_y': True}]])
fig_duration.add_trace(go.Bar(
    x=monthly_duration['Month'],
    y=monthly_duration['AvgDuration'],
    name='Avg Duration (days)',
    marker_color=colors['Cornflower'][-1],
    opacity=0.7,
    text=monthly_duration['AvgDuration'].round(1),
    textposition='outside'
), secondary_y=False)

fig_duration.add_trace(go.Scatter(
    x=monthly_duration['Month'],
    y=monthly_duration['Deals'],
    mode='lines',
    name='Closed Deals Count',
    line=dict(color=colors['Tomato'][-1], width=3),
    text=monthly_duration['Deals'],
    textposition='top center'
), secondary_y=True)

fig_duration.update_layout(
    title='Average Deal Duration and Deal Count by Month',
    title_x=0.5,
    width=950,
    height=450,
    template='plotly_white',
    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
)
fig_duration.update_yaxes(title_text="Avg Duration (days)", secondary_y=False)
fig_duration.update_yaxes(title_text="Deals Count", secondary_y=True)
fig_duration.show()

"""The chart shows that **months with higher closed deal counts tend to have longer average deal durations**.  
For example, peaks in closed deals around **April–May 2024** coincide with the highest average deal durations (15–18 days).  
This suggests that **successful deals require more time**, likely due to deeper communication, nurturing, and decision-making processes.  
Meanwhile, periods with shorter average durations (e.g., early months) correspond to lower deal volume, indicating **quick deals often end earlier without closing**.

**Insight:**  
A longer deal cycle is not a problem — **it is associated with higher success**.  
Focusing on **consistent follow-up and sustained engagement** can help increase the closing rate.
"""

deals_source_month = (
    df_deals[df_deals['Closing Date'].notna()]
    .assign(Month=df_deals['Closing Date'].dt.to_period('M').dt.to_timestamp())
    .groupby(['Month', 'Source'])
    .size()
    .reset_index(name='Deals Count')
)

pivot_source = deals_source_month.pivot(
    index='Source',
    columns='Month',
    values='Deals Count'
).fillna(0)

z = pivot_source.values
x = [d.strftime('%b %Y') for d in pivot_source.columns]
y = pivot_source.index.tolist()
text = [[f'{int(v):,}' for v in row] for row in z]

colors = get_my_palette(as_dict=True)

fig = go.Figure()

fig.add_trace(go.Heatmap(
    z=z,
    x=x,
    y=y[::-1],
    text=text[::-1],
    texttemplate='<b>%{text}</b>',
    textfont={'size': 9},
    zmin=z.min(),
    zmax=z.max(),
    colorscale=[
        [0.0, colors['Yellowsoft'][3]],
        [0.3, colors['Lavender'][3]],
        [0.6, colors['Cornflower'][3]],
        [1.0, colors['Lime Green'][3]]
    ],
    colorbar=dict(
        title='Deals Count',
        titleside='right',
        titlefont=dict(size=12),
        tickfont=dict(size=10),
        len=0.75,
        thickness=18,
        outlinewidth=0
    ),
    hovertemplate='Month: %{x}<br>Source: %{y}<br>Deals: %{z}<extra></extra>'
))

fig.update_layout(
    title='Closed Deals by Source and Month',
    title_x=0.5,
    title_font=dict(size=18),
    template='plotly_white',
    width=950,
    height=700,
    xaxis=dict(
        title='Month',
        tickangle=-45,
        tickfont=dict(size=9),
        showgrid=False
    ),
    yaxis=dict(
        title='Source',
        tickfont=dict(size=9),
        showgrid=False
    ),
    margin=dict(l=80, r=50, t=80, b=60)
)

fig.show()

deals_source_month = (
    df_deals[df_deals['Closing Date'].notna()]
    .assign(Month=df_deals['Closing Date'].dt.to_period('M').dt.to_timestamp())
    .groupby(['Month', 'Source'])
    .size()
    .reset_index(name='Deals Count')
)

pivot_source = deals_source_month.pivot(
    index='Source',
    columns='Month',
    values='Deals Count'
).fillna(0)

df_deals['Is Successful'] = df_deals['Stage'].str.lower().eq('payment done')

success_source_month = (
    df_deals[df_deals['Closing Date'].notna()]
    .assign(Month=df_deals['Closing Date'].dt.to_period('M').dt.to_timestamp())
    .groupby(['Month', 'Source'])['Is Successful']
    .sum()
    .reset_index(name='Successful Deals')
)

pivot_success = success_source_month.pivot(
    index='Source',
    columns='Month',
    values='Successful Deals'
).fillna(0)

z_success = pivot_success.reindex(index=pivot_source.index, columns=pivot_source.columns, fill_value=0).values

x = [d.strftime('%b %Y') for d in pivot_source.columns]
y = pivot_source.index.tolist()
text = [[f"{int(v):,}" for v in row] for row in pivot_source.values]

colors = get_my_palette(as_dict=True)

fig = go.Figure()

fig.add_trace(go.Heatmap(
    z=z_success,
    x=x,
    y=y[::-1],
    text=text[::-1],
    texttemplate='<b>%{text}</b>',
    textfont={'size': 9},
    zmin=z_success.min(),
    zmax=z_success.max(),
    colorscale=[
        [0.0, colors['Yellowsoft'][3]],
        [0.3, colors['Lavender'][3]],
        [0.6, colors['Cornflower'][3]],
        [1.0, colors['Lime Green'][3]]
    ],
    colorbar=dict(
        title='Deals Count',
        titleside='right',
        titlefont=dict(size=12),
        tickfont=dict(size=10),
        len=0.75,
        thickness=18,
        outlinewidth=0
    ),
    hovertemplate='Month: %{x}<br>Source: %{y}<br>Deals: %{z}<extra></extra>'
))

fig.update_layout(
    title='Closed Deals by Source and Month',
    title_x=0.5,
    title_font=dict(size=18),
    template='plotly_white',
    width=950,
    height=700,
    xaxis=dict(
        title='Month',
        tickangle=-45,
        tickfont=dict(size=9),
        showgrid=False
    ),
    yaxis=dict(
        title='Source',
        tickfont=dict(size=9),
        showgrid=False
    ),
    margin=dict(l=80, r=50, t=80, b=60)
)

fig.show()

conversion_source = (
    df_deals.groupby('Source')
    .agg(
        Deals=('Id', 'count'),
        Successful=('Stage', lambda x: (x.astype(str).str.lower() == 'payment done').sum())
    )
    .assign(Conversion=lambda d: (d['Successful'] / d['Deals'] * 100).round(1))
    .sort_values('Conversion', ascending=False)
    .reset_index()
)

colors = get_my_palette(as_dict=True)
bar_color = colors['Cornflower'][3]

fig_conv = px.bar(
    conversion_source,
    x='Source',
    y='Conversion',
    text='Conversion',
    title='Conversion Rate by Source',
    labels={'Conversion': 'Conversion Rate (%)'}
)

fig_conv.update_traces(
    marker_color=bar_color,
    texttemplate='%{text:.1f}%',
    textposition='outside'
)

fig_conv.update_layout(
    yaxis_title='Conversion Rate (%)',
    xaxis_title='Source',
    width=950,
    height=450,
    template='plotly_white',
    showlegend=False,
    title_x=0.5
)

fig_conv.show()

"""Conversion Rate by Source — Key Insights

- **Webinars (11.6%)** and **Organic (11.0%)** deliver the **highest conversion rates**.  
  These leads arrive **pre-qualified and motivated**, indicating strong trust and relevance in these channels.

- **SMM (6.2%)** performs moderately well, but still lags behind the top sources.  
  There is potential to improve results through **better audience targeting and warm-up communication**.

- **Paid advertising channels** (Facebook Ads, Google Ads, Telegram posts, Bloggers, YouTube Ads, TikTok Ads) show **lower conversion rates (3–4%)**.  
  These leads are generally **colder** and require **more nurturing and qualification** before closing.

- **CRM, Partnership, and Offline** channels demonstrate **the lowest conversion performance**, suggesting they are either underutilized or not structured effectively.

### Conclusion
For the strongest business impact, focus on **scaling Webinars and Organic channels**, while **enhancing lead nurturing and qualification processes** for paid advertising traffic.
"""

df = df_deals.copy()
df['Time_to_Close'] = (df['Closing Date'] - df['Created Time']).dt.days.abs()

last_date_in_df = df['Created Time'].max()

open_successful = df[(df['Stage'] == 'Payment Done') & (df['Closing Date'].isna())]
open_days = (last_date_in_df - open_successful['Created Time']).dt.days

successful_closed = df.loc[df['Stage'] == 'Payment Done', 'Time_to_Close'].dropna()
lost_closed = df.loc[df['Stage'] == 'Lost', 'Time_to_Close'].dropna()

colors = get_my_palette(as_dict=True)
color_map = {
    'Successful Opened': colors['Lime Green'][3],
    'Successful Closed': colors['Cornflower'][3],
    'Lost': colors['Tomato'][3]
}

group_labels = ['Successful Opened', 'Successful Closed', 'Lost']
hist_data = [open_days, successful_closed, lost_closed]
ridge_colors = [color_map[label] for label in group_labels]

fig = go.Figure()
offset = 1.0
alpha = 0.9
line_width = 8

for i, (data, label, color) in enumerate(zip(hist_data, group_labels, ridge_colors)):
    if len(data) == 0:
        continue
    y = np.full_like(data, len(group_labels) - 1 - i)
    fig.add_trace(go.Scattergl(
        x=data,
        y=y,
        mode='markers',
        marker=dict(
            symbol='line-ns-open',
            line=dict(color=color, width=line_width),
            opacity=alpha
        ),
        name=label,
        showlegend=False
    ))

for i, label in enumerate(group_labels):
    fig.add_annotation(
        xref='paper', yref='y',
        x=-0.12,
        y=len(group_labels) - 1 - i,
        text=label,
        showarrow=False,
        font=dict(size=13, color='black')
    )

fig.update_layout(
    title='Deal Closing Distribution by Status',
    title_x=0.5,
    width=950,
    height=400,
    plot_bgcolor='white',
    yaxis=dict(
        showticklabels=False,
        showgrid=False,
        zeroline=False,
        range=[-0.5, len(hist_data) * offset]
    ),
    xaxis=dict(
        title='Days to Close',
        showgrid=True,
        zeroline=False
    ),
    margin=dict(l=140, r=30, t=60, b=50)
)

fig.show()

"""**Deal Closing Distribution — Summary**

Closed (successful) deals usually close within **30–150 days**, showing a stable and predictable conversion cycle.

Lost deals are mostly closed within 0–200 days, meaning many conversations are dropped before reaching later decision stages.

Open successful deals have many cases lasting 200+ days, indicating delayed or slow-moving opportunities.

**Conclusion:**
Successful deals require time and consistent follow-up, while long-running open deals may need re-evaluation or stronger push to avoid stagnation.
"""

log_section('=== Campaign effectiveness ===')
start_time = time.time()

"""# === Campaign effectiveness ==="""

df_deals['Is Successful'] = df_deals['Stage'].str.lower().eq('payment done')

deals_total = (
    df_deals.groupby('Source')
    .agg({
        'Contact Name': 'count',
        'Campaign': 'nunique',
        'Offer Total Amount': 'sum',
        'Initial Amount Paid': 'sum'
    })
    .rename(columns={
        'Contact Name': 'Deals Count',
        'Campaign': 'Campaigns Count',
        'Offer Total Amount': 'Total Offer Amount',
        'Initial Amount Paid': 'Total Paid'
    })
)

deals_success = (
    df_deals[df_deals['Is Successful']]
    .groupby('Source')
    .agg({
        'Contact Name': 'count',
        'Offer Total Amount': 'sum',
        'Initial Amount Paid': 'sum'
    })
    .rename(columns={
        'Contact Name': 'Successful Deals',
        'Offer Total Amount': 'Total Offer Amount (Success)',
        'Initial Amount Paid': 'Total Paid (Success)'
    })
)

spend_grouped = (
    df_spend.groupby('Source')
    .agg({
        'Impressions': 'sum',
        'Clicks': 'sum',
        'Spend': 'sum'
    })
)

campaign_summary = (
    deals_total
    .merge(deals_success, on='Source', how='outer')
    .merge(spend_grouped, on='Source', how='outer')
    .fillna(0)
    .reset_index()
)

campaign_summary['Conversion Rate (%)'] = (
    campaign_summary['Successful Deals'] / campaign_summary['Deals Count'] * 100
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['ROI (%)'] = (
    campaign_summary['Total Paid (Success)'] / campaign_summary['Spend'] * 100
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

cols_order = [
    'Source',
    'Campaigns Count',
    'Deals Count',
    'Successful Deals',
    'Clicks',
    'Impressions',
    'Total Offer Amount',
    'Total Paid',
    'Total Offer Amount (Success)',
    'Total Paid (Success)',
    'Spend',
    'Conversion Rate (%)',
    'ROI (%)'
]

campaign_summary = campaign_summary[cols_order].sort_values('ROI (%)', ascending=False)

display(campaign_summary.style.format({
    'Conversion Rate (%)': '{:.2f}%',
    'ROI (%)': '{:.2f}%',
    'Spend': '{:,.0f}',
    'Total Paid': '{:,.0f}',
    'Total Paid (Success)': '{:,.0f}',
    'Total Offer Amount': '{:,.0f}',
    'Total Offer Amount (Success)': '{:,.0f}'
}))

"""**Webinar and SMM** deliver the best profitability.
→ These channels should be prioritized and scaled carefully.

**Facebook and Google drive** scale but weaken margin.
→ Improve lead qualification, nurturing, and closing scripts.

**Telegram and TikTok** are promising but require structured content and warm-up strategies.

**Organic** traffic is a high-value strategic asset — increasing brand visibility will pay off.

**CRM and Partnership** channels have growth potential if retention and referral mechanics are strengthened.

**Business Summary**

The funnel is scaling successfully, but profitability depends on improving closing efficiency in high-spend ad channels while expanding high-ROI warm-audience sources (Webinar / SMM / Organic).
"""

campaign_summary['CR (%)'] = (
    campaign_summary['Successful Deals'] / campaign_summary['Deals Count'] * 100
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['CTR (%)'] = (
    campaign_summary['Clicks'] / campaign_summary['Impressions'] * 100
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['CPC (€)'] = (
    campaign_summary['Spend'] / campaign_summary['Clicks']
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['CPL (€)'] = (
    campaign_summary['Spend'] / campaign_summary['Deals Count']
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['CPA (€)'] = (
    campaign_summary['Spend'] / campaign_summary['Successful Deals']
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary['ROI (%)'] = (
    (campaign_summary['Total Paid (Success)'] - campaign_summary['Spend']) / campaign_summary['Spend'] * 100
).replace([np.inf, -np.inf], np.nan).fillna(0).round(2)

campaign_summary_sorted = campaign_summary.sort_values(by='Deals Count', ascending=False)

cornflower = get_my_palette(group='Cornflower')[3]
tomato = get_my_palette(group='Tomato')[3]
lavender = get_my_palette(group='Lavender')[3]
lime = get_my_palette(group='Lime Green')[3]

fig, axes = plt.subplots(ncols=2, figsize=(14, 5), dpi=100)

sns.barplot(
    data=campaign_summary_sorted,
    x='Source', y='Deals Count',
    color=cornflower, alpha=0.9, ax=axes[0]
)
axes[0].set_title('Number of Deals by Source', fontsize=12, pad=10, weight='bold')
axes[0].set_xlabel('')
axes[0].set_ylabel('Number of Deals', fontsize=9)
axes[0].tick_params(axis='x', rotation=45, labelsize=8)
axes[0].tick_params(axis='y', labelsize=8)
axes[0].grid(axis='y', linestyle=':', alpha=0.4)
axes[0].bar_label(axes[0].containers[0], fmt='%.0f', fontsize=8, padding=2)

sns.barplot(
    data=campaign_summary_sorted,
    x='Source', y='CR (%)',
    color=lime, alpha=0.9, ax=axes[1]
)
axes[1].set_title('Conversion by Source (CR)', fontsize=12, pad=10, weight='bold')
axes[1].set_xlabel('')
axes[1].set_ylabel('CR (%)', fontsize=9)
axes[1].tick_params(axis='x', rotation=45, labelsize=8)
axes[1].tick_params(axis='y', labelsize=8)
axes[1].grid(axis='y', linestyle=':', alpha=0.4)
axes[1].bar_label(axes[1].containers[0], fmt='%.2f', fontsize=8, padding=2)

plt.tight_layout()
save_plot('cr_and_deals_by_source', subfolder='notebooks')
plt.show()

plt.figure(figsize=(10, 4), dpi=100)
sns.barplot(
    data=campaign_summary_sorted,
    x='Source', y='CTR (%)',
    color=tomato, alpha=0.9
)
plt.title('Click-Through Rate by Source (CTR)', fontsize=12, pad=10, weight='bold')
plt.xlabel('')
plt.ylabel('CTR (%)', fontsize=9)
plt.xticks(rotation=45, fontsize=8)
plt.yticks(fontsize=8)
plt.grid(axis='y', linestyle=':', alpha=0.4)
plt.bar_label(plt.gca().containers[0], fmt='%.2f', fontsize=8, padding=2)
sns.despine()
plt.tight_layout()
save_plot('ctr_by_source', subfolder='notebooks')
plt.show()

"""**Deals & Conversion by Source — Key Takeaways**

**Facebook Ads and Google Ads** generate the largest number of deals, but their conversion rates are low → high volume, low efficiency.

**Organic and Webinar** sources show the highest conversion rates (~11%), meaning these leads are warmer and more qualified.

Mid-range channels (**SMM, Bloggers, Telegram Posts**) provide steady but moderate results.

**Offline and Radio** show no meaningful contribution.

**Conclusion:**
Paid ads scale the funnel, but the most effective and profitable leads come from Organic and Webinar sources. Focus on strengthening high-conversion channels while improving qualification in paid traffic.

**CTR Analysis by Source**

SMM stands out strongly with a CTR **of ~48%**, indicating very high audience engagement.
Most other channels show low CTR (0.5–2.5%), meaning users click far less frequently.
**Telegram posts** and Bloggers perform moderately better (2.3% and 1.9%) compared to the rest.
Organic, CRM, Webinar, Offline, and Radio show near-zero CTR, suggesting these channels either don’t generate interest or the format isn’t click-driven.

**Conclusion:**
Channels with high CTR (especially SMM) should be prioritized for driving traffic and awareness.
Low-CTR sources likely require creative optimization, better targeting, or strategic repositioning.
"""

cornflower = get_my_palette(group='Cornflower')
lime = get_my_palette(group='Lime Green')
tomato = get_my_palette(group='Tomato')
lavender = get_my_palette(group='Lavender')

all_colors = (
    cornflower + lime + tomato + lavender
)

sources = campaign_summary['Source'].unique()
colors_repeated = (all_colors * ((len(sources) // len(all_colors)) + 1))[:len(sources)]

custom_palette = dict(zip(sources, colors_repeated))

plt.figure(figsize=(8, 5), dpi=100)
sns.scatterplot(
    data=campaign_summary,
    x='Spend',
    y='Deals Count',
    hue='Source',
    palette=custom_palette,
    s=110,
    edgecolor='white',
    linewidth=0.8,
    alpha=0.9
)

plt.title('Relationship Between Number of Deals and Advertising Spend', fontsize=14, pad=12)
plt.xlabel('Spend', fontsize=10)
plt.ylabel('Deals count', fontsize=10)
plt.grid(axis='both', linestyle=':', alpha=0.4, zorder=0)
plt.legend(title='Source', fontsize=8, title_fontsize=9, loc='upper left', frameon=False)
plt.tick_params(axis='both', labelsize=8)

sns.despine()
plt.tight_layout()
save_plot('deals_vs_spend', subfolder='notebooks')
plt.show()

"""There is a moderate positive correlation between spend and the number of deals: higher budgets generally lead to more leads.

**Facebook Ads and Google Ads** appear in the upper-right area — these channels require significant investment but generate a high volume of deals.

**SMM and Telegram** posts demonstrate high efficiency at low cost, delivering strong results with minimal spend.

**Webinar, Organic, and CRM** channels require almost no financial investment but still generate deals.

**Partnership and Offline** do not produce results — likely due to inactive or ineffective campaigns.

**Conclusion:**

SMM and Telegram are the most cost-efficient channels (low spend, high return).
Facebook and Google deliver high deal volume but at a higher cost.
"""

metrics = ['Spend', 'CR (%)', 'CTR (%)', 'CPC (€)', 'CPL (€)','CPA (€)', 'ROI (%)']
corr_matrix = campaign_summary[metrics].corr().round(2)
abs_corr = corr_matrix.abs()

lavender = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')
lime = get_my_palette(group='Lime Green')
cornflower = get_my_palette(group='Cornflower')

cmap_custom = LinearSegmentedColormap.from_list(
    'marketing_corr_map',
    cornflower + tomato + lavender + lime
)

plt.figure(figsize=(8, 6), dpi=100)
ax = sns.heatmap(
    corr_matrix,
    annot=True,
    fmt='.2f',
    cmap=cmap_custom,
    center=0,
    linewidths=0.4,
    annot_kws={'size': 8, 'weight': 'bold'},
    cbar_kws={'label': 'Correlation', 'shrink': 0.8, 'aspect': 25, 'pad': 0.02}
)

for i in range(len(corr_matrix)):
    ax.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor=lime[-1], lw=1.2))

for y, x in zip(*np.where(abs_corr > 0.8)):
    ax.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor=tomato[-1], lw=1.3, linestyle='--'))

ax.set_title('Correlation Between Marketing Metrics', fontsize=14, pad=12)
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)
ax.collections[0].colorbar.ax.tick_params(labelsize=8)
ax.collections[0].colorbar.ax.set_ylabel('Correlation Coefficient', fontsize=8)

sns.despine()
plt.tight_layout()

save_plot('marketing_metrics_correlation', subfolder='notebooks')
plt.show()

"""**Spend ↔ CPA** (0.71) and *Spend ↔ CPL *(0.65) show strong positive correlations: the more we spend, the higher the cost per lead and cost per acquisition.

**CTR ↔ ROI** (0.56) and **CPC ↔ ROI** (0.72) indicate that engagement quality and click cost have a significant impact on return on investment.

**CPL ↔ CPA** (0.89) is a very strong correlation, confirming that cost metrics within the funnel are consistent and move together.

**Spend ↔ ROI **(0.04) shows virtually no relationship: increasing the advertising budget does not guarantee higher returns.

**Conversion Rate (CR) **shows weak correlations with other metrics, suggesting that lead quality is determined more by post-lead processes (scripts, follow-ups, CRM handling) rather than by traffic alone.

**Conclusion:**

ROI is driven primarily by CTR and CPC rather than budget size.
This means creative quality and precise targeting are the key drivers of performance, not simply increasing spend.
"""

lavender = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')
lime = get_my_palette(group='Lime Green')
cornflower = get_my_palette(group='Cornflower')

colors_combined = tomato + cornflower + lime
color_scale = [
    [i / (len(colors_combined) - 1), color]
    for i, color in enumerate(colors_combined)
]

df_plot = campaign_summary.copy()
df_plot = df_plot[df_plot['Deals Count'] > 0]

fig = px.scatter(
    df_plot,
    x='Deals Count',
    y='CR (%)',
    size='Successful Deals',
    color='ROI (%)',
    hover_name='Source',
    text='Source',
    color_continuous_scale=color_scale,
    title='Campaign Effectiveness Landscape: Deals, Conversion, and ROI',
    labels={
        'Deals Count': 'Number of Deals',
        'CR (%)': 'Conversion Rate (CR, %)',
        'ROI (%)': 'Return on Investment (ROI, %)',
        'Successful Deals': 'Successful Deals'
    },
    size_max=55,
    height=600
)

fig.update_traces(
    marker=dict(line=dict(width=1, color='white')),
    textposition='top center',
    textfont=dict(size=11, color='black'),
    opacity=0.85,
    hovertemplate=(
        '<b>%{hovertext}</b><br>'
        'Deals: %{x}<br>'
        'CR: %{y:.1f}%<br>'
        'ROI: %{marker.color:.1f}%<br>'
        'Successful Deals: %{marker.size}<extra></extra>'
    )
)

fig.update_layout(
    xaxis=dict(
        title='Number of Deals',
        showgrid=True,
        zeroline=False,
        gridcolor='rgba(0,0,0,0.1)',
        tickfont=dict(size=11)
    ),
    yaxis=dict(
        title='Conversion Rate (CR, %)',
        showgrid=True,
        zeroline=False,
        gridcolor='rgba(0,0,0,0.1)',
        tickfont=dict(size=11)
    ),
    plot_bgcolor='rgb(248,248,245)',
    coloraxis_colorbar=dict(title='ROI (%)'),
    font=dict(size=12, color='#333'),
    hoverlabel=dict(bgcolor='white', font_size=11),
    margin=dict(l=60, r=60, t=70, b=60)
)

median_x = df_plot['Deals Count'].median()
median_y = df_plot['CR (%)'].median()

fig.add_vline(
    x=median_x,
    line_dash='dot',
    line_color=get_my_palette(group='Cornflower')[3],
    annotation_text='Median Deals',
    annotation_position='bottom left',
    layer='below'
)
fig.add_hline(
    y=median_y,
    line_dash='dot',
    line_color=get_my_palette(group='Cornflower')[3],
    annotation_text='Median CR',
    annotation_position='top right',
    layer='below'
)

fig.add_annotation(
    x=median_x * 4, y=median_y * 3,
    text='High Volume / High CR',
    showarrow=False,
    font=dict(size=11, weight='bold')
)
fig.add_annotation(
    x=median_x * 0.65, y=median_y * 3,
    text='Low Volume / High CR',
    showarrow=False,
    font=dict(size=11, weight='bold')
)
fig.add_annotation(
    x=median_x * 4, y=median_y * 0.2,
    text='High Volume / Low CR',
    showarrow=False,
    font=dict(size=11, weight='bold')
)
fig.add_annotation(
    x=median_x * 0.65, y=median_y * 0.2,
    text='Low Volume / Low CR',
    showarrow=False,
    font=dict(size=11, weight='bold')
)

fig.show()

top_performers = df_plot.sort_values(['ROI (%)', 'CR (%)'], ascending=False).head(5)

display(
    top_performers[
        ['Source', 'Deals Count', 'CR (%)', 'ROI (%)', 'CPC (€)', 'CPA (€)']
    ].style.background_gradient(
        cmap='RdYlGn', subset=['ROI (%)', 'CR (%)']
    ).format({
        'CR (%)': '{:.2f}%',
        'ROI (%)': '{:.2f}%',
        'CPC (€)': '{:.2f}',
        'CPA (€)': '{:.2f}'
    })
)

"""**Facebook Ads & Google Ads** → many deals, but low efficiency. Good for scale, but need conversion optimization.

**SMM, Organic, Webinar** → best performance: high conversion and ROI. These channels should be prioritized and scaled.

**Telegram, Bloggers, CRM** → average results. Keep, but without major investment.

**TikTok & YouTube Ads** → low CR and weak ROI → need creative/targeting rework.

**Partnership & Offline** → no value → can be paused.

**Bottom line:**
Focus growth efforts on SMM + Organic + Webinar, and improve conversion quality in Facebook & Google campaigns
"""

df = df_deals.copy()

df = df[df['Campaign'] != 'Unknown'].copy()
df['is_success'] = df['Stage'].str.lower().eq('payment done')

agg_campaigns = (
    df.groupby('Campaign')
    .agg(
        total_leads=('Id', 'count'),
        successful=('is_success', 'sum')
    )
    .reset_index()
)

agg_campaigns = agg_campaigns[agg_campaigns['total_leads'] >= 30]

agg_campaigns['conversion_rate'] = (
    agg_campaigns['successful'] / agg_campaigns['total_leads'] * 100
).round(2)

top10_campaigns = agg_campaigns.sort_values('conversion_rate', ascending=False).head(10)

lavender = get_my_palette(group='Lavender')[2]
tomato = get_my_palette(group='Tomato')[3]

plt.figure(figsize=(8, 4), dpi=100)
bars = sns.barplot(
    data=top10_campaigns,
    y='Campaign', x='conversion_rate',
    palette=[lavender]*len(top10_campaigns)
)

plt.title('Top 10 Campaigns by Conversion Rate (≥ 30 Leads)', fontsize=14, pad=12)
plt.xlabel('Conversion Rate (%)', fontsize=8)
plt.ylabel('Campaign', fontsize=8)
plt.xticks(fontsize=8)
plt.yticks(fontsize=8)
plt.grid(axis='x', linestyle=':', alpha=0.4)

avg_conv = top10_campaigns['conversion_rate'].mean()
plt.axvline(avg_conv, color=tomato, linestyle='--', linewidth=1)
plt.text(avg_conv + 0.3, 0.2, f'Average: {avg_conv:.2f}%', fontsize=9)

for p in bars.patches:
    plt.text(
        p.get_width() + 0.3,
        p.get_y() + p.get_height()/2,
        f'{p.get_width():.2f}%',
        va='center', fontsize=8, color='black'
    )

sns.despine()
plt.tight_layout()
plt.show()

"""This chart highlights the top-performing campaigns by conversion rate (≥ 30 leads).
The average conversion rate across campaigns is ~7.25%.

**web2408_DE, brand_search_eng_DE, and web2211_DE** stand out with significantly above-average performance (**9–11%**) — these campaigns are strong benchmarks.

Campaigns below the average (**≈5–6%**) such as **Bloggernina_DE** and Dis_DE are still performing, but may need targeting or messaging optimization.

**Key Insight**

There is a clear separation between high-efficiency and mid-efficiency campaigns.
Focusing on what differentiates the top three (audience, creative, offer) can help raise the performance of the rest.

**Overall Conclusion**

Mass-marketing channels (**Facebook, Google**) deliver volume but not necessarily quality — their efficiency is strongly dependent on budget.

**SMM, Webinars, and Telegram** posts are strategic growth drivers: they show high ROI and strong engagement at low cost.

**Organic** delivers the highest-quality leads — investing in SEO and content marketing should be a priority.

**TikTok and YouTube Ads** require creative and messaging optimization — they show low CTR and CR despite relatively high spend.

The key success factors across campaigns are:
content quality (CTR), precise targeting, and consistent lead follow-up processes.

# Sales Department Performance Analysis
"""

df_deals['Is Successful'] = df_deals['Stage'].str.lower().eq('payment done')

deal_owner_agg = (
    df_deals
    .groupby("Deal Owner Name")
    .agg(
        total_deals=('Id', 'count'),
        success_count=('Is Successful', 'sum'),
        total_amount=('Offer Total Amount', 'sum'),
        avg_sla_h=('SLA Hours', 'mean')
    )
    .reset_index()
)
colors = get_my_palette(as_dict=True)
tomato = colors['Tomato']
cornflower = colors['Cornflower']
lime = colors['Lime Green']

my_cmap = LinearSegmentedColormap.from_list(
    'my_efficiency_map',
    [tomato[3], tomato[2], cornflower[2], lime[2], lime[3]]
)

deal_owner_agg['conversion'] = (
    deal_owner_agg['success_count'] / deal_owner_agg['total_deals']
).fillna(0) * 100
deal_owner_agg['avg_amount_per_deal'] = (
    deal_owner_agg['total_amount'] / deal_owner_agg['total_deals']
).fillna(0)

heat_df = deal_owner_agg[['Deal Owner Name', 'total_amount', 'conversion']].copy()
heat_df['conversion'] = heat_df['conversion'] / 100

heat_df['normalized_amount'] = (heat_df['total_amount'] - heat_df['total_amount'].min()) / (
    heat_df['total_amount'].max() - heat_df['total_amount'].min()
)
heat_df['normalized_conversion'] = (heat_df['conversion'] - heat_df['conversion'].min()) / (
    heat_df['conversion'].max() - heat_df['conversion'].min()
)

heat_df['efficiency_index'] = (
    (heat_df['normalized_amount'] * 0.6) + (heat_df['normalized_conversion'] * 0.4)
) * 100

summary_df = deal_owner_agg.merge(
    heat_df[['Deal Owner Name', 'efficiency_index']],
    on='Deal Owner Name',
    how='left'
)

summary_df = summary_df.sort_values(by='efficiency_index', ascending=False)

summary_df_display = summary_df.copy()
summary_df_display['conversion'] = summary_df_display['conversion'].round(2)
summary_df_display['avg_sla_h'] = summary_df_display['avg_sla_h'].round(1)
summary_df_display['avg_amount_per_deal'] = summary_df_display['avg_amount_per_deal'].round(2)
summary_df_display['efficiency_index'] = summary_df_display['efficiency_index'].round(1)

display(
    summary_df_display[
        [
            'Deal Owner Name', 'total_deals', 'success_count',
            'conversion', 'total_amount', 'avg_amount_per_deal',
            'avg_sla_h', 'efficiency_index'
        ]
    ]
    .style.background_gradient(
        cmap=my_cmap, subset=['conversion', 'efficiency_index']
    )
    .format({
        'conversion': '{:.2f}%',
        'total_amount': '{:,.0f} €',
        'avg_amount_per_deal': '{:,.2f} €',
        'avg_sla_h': '{:.1f} h',
        'efficiency_index': '{:.1f}'
    })
)

"""**Sales Team Performance Insights**

*Top performers by efficiency:* <br>
**Ulysses Adams and Charlie Davis** lead the team — they maintain high total deal volume and solid closing efficiency, resulting in the highest efficiency indexes (68.4 and 61.6). Their workflow speed (avg SLA hours) is also balanced.

*High conversion but low volume:*
**Oliver Taylor (33.86%) and John Doe (25%)** have very strong conversion rates, but manage very few deals. Their methods could be standardized and shared with the wider team.

*Mid-level group:*
**Julia Nelson, Paula Underwood, and Ben Hall** show steady deal flow but below-average conversion rates (3–5%). These reps may benefit from closing skill training or lead qualification refinement.

*Underperformers:*
**Daniel Evans, Eva Kent, Ian Miller**, and others show both low conversion and low efficiency. Some also have very high SLA times, indicating slow pipeline movement.

*Key bottleneck indicator:*
Lower efficiency strongly correlates with long avg SLA hours — the slower the deal moves, the less likely it closes.
"""

df_deals['Is Successful'] = df_deals['Stage'].str.lower().eq('payment done')
df = df_deals[df_deals['Campaign'].notna() & (df_deals['Campaign'] != 'Unknown')].copy()

manager_campaign_conv = (
    df.groupby(['Deal Owner Name', 'Campaign'])
    .agg(
        total_deals=('Id', 'count'),
        success_count=('Is Successful', 'sum')
    )
    .reset_index()
)

manager_campaign_conv['conversion'] = (
    manager_campaign_conv['success_count'] / manager_campaign_conv['total_deals']
).fillna(0) * 100

top10_campaigns = (
    manager_campaign_conv.groupby('Campaign')['conversion']
    .mean()
    .sort_values(ascending=False)
    .head(10)
    .index
)

heat_df = manager_campaign_conv[manager_campaign_conv['Campaign'].isin(top10_campaigns)]

colors = get_my_palette(as_dict=True)
tomato = colors['Tomato']
cornflower = colors['Cornflower']
lime = colors['Lime Green']

heat_colors = [
    [0.0, tomato[0]],
    [0.25, tomato[3]],
    [0.5, cornflower[2]],
    [0.75, lime[1]],
    [1.0, lime[3]]
]

pivot_conv = heat_df.pivot_table(
    index='Deal Owner Name',
    columns='Campaign',
    values='conversion',
    fill_value=0
)

fig_conv = px.imshow(
    pivot_conv,
    color_continuous_scale=heat_colors,
    text_auto='.1f',
    aspect='auto',
    title='Conversion Rate by Manager and Top-10 Campaigns',
    labels=dict(x='Campaign', y='Deal Owner', color='Conversion Rate (%)'),
    height=700
)

fig_conv.update_traces(
    hovertemplate='<b>%{y}</b><br>Campaign: %{x}<br>Conversion: %{z:.1f}%<extra></extra>'
)
fig_conv.update_layout(
    template='plotly_white',
    font=dict(size=12, color='#333'),
    plot_bgcolor='rgb(250,250,248)',
    coloraxis_colorbar=dict(title='Conversion (%)'),
    margin=dict(l=80, r=60, t=70, b=60)
)
fig_conv.update_xaxes(side='bottom', tickangle=-45)
fig_conv.show()

pivot_deals = heat_df.pivot_table(
    index='Deal Owner Name',
    columns='Campaign',
    values='total_deals',
    fill_value=0
)

fig_deals = px.imshow(
    pivot_deals,
    color_continuous_scale=heat_colors,
    text_auto='.0f',
    aspect='auto',
    title='Total Deals by Manager and Top-10 Campaigns',
    labels=dict(x='Campaign', y='Deal Owner', color='Number of Deals'),
    height=700
)

fig_deals.update_traces(
    hovertemplate='<b>%{y}</b><br>Campaign: %{x}<br>Total Deals: %{z}<extra></extra>'
)
fig_deals.update_layout(
    template='plotly_white',
    font=dict(size=12, color='#333'),
    plot_bgcolor='rgb(250,250,248)',
    coloraxis_colorbar=dict(title='Number of Deals'),
    margin=dict(l=80, r=60, t=70, b=60)
)
fig_deals.update_xaxes(side='bottom', tickangle=-45)
fig_deals.show()

df = df_deals[df_deals['Campaign'].notna() & (df_deals['Campaign'] != 'Unknown')].copy()

manager_campaign = (
    df.groupby(['Deal Owner Name', 'Campaign'])
    .agg(
        total_deals=('Id', 'count')
    )
    .reset_index()
)

top10_campaigns = (
    manager_campaign.groupby('Campaign')['total_deals']
    .sum()
    .sort_values(ascending=False)
    .head(10)
    .index
)

heat_df = manager_campaign[manager_campaign['Campaign'].isin(top10_campaigns)]

colors = get_my_palette(as_dict=True)
tomato = colors['Tomato']
cornflower = colors['Cornflower']
lime = colors['Lime Green']

heat_colors = [
    [0.0, tomato[0]],
    [0.25, tomato[3]],
    [0.5, cornflower[2]],
    [0.75, lime[1]],
    [1.0, lime[3]]
]

pivot_deals = heat_df.pivot_table(
    index='Deal Owner Name',
    columns='Campaign',
    values='total_deals',
    fill_value=0
)

fig = px.imshow(
    pivot_deals,
    color_continuous_scale=heat_colors,
    text_auto='.0f',
    aspect='auto',
    title='Total Deals by Manager and Top-10 Campaigns',
    labels=dict(x='Campaign', y='Deal Owner', color='Number of Deals'),
    height=900
)

fig.update_traces(
    hovertemplate='<b>%{y}</b><br>Campaign: %{x}<br>Total Deals: %{z}<extra></extra>'
)
fig.update_layout(
    template='plotly_white',
    font=dict(size=12, color='#333'),
    plot_bgcolor='rgb(250,250,248)',
    coloraxis_colorbar=dict(title='Number of Deals'),
    margin=dict(l=80, r=60, t=70, b=60)
)
fig.update_xaxes(side='bottom', tickangle=-45)
fig.show()

"""**Analysis: Manager Performance Across Top Campaigns**

**Charlie Davis, Julia Nelson, and Ulysses Adams** consistently perform well across many campaigns.
→ These are high-versatility, high-productivity managers.

**Paula Underwood, Quincy Vincent, and Nina Scott** show strong results only in specific campaigns.
→ Their performance depends on traffic relevance and lead quality.

**Ben Hall and Jane Smith** maintain stable, mid-level performance across sources.
→ They are reliable for steady handling and new campaign testing.

**Eva Kent, Mason Roberts, Alice Johnson**, and several others show consistently low results across campaigns.
→ These managers require coaching, script improvement, or revised workload allocation.

# Analysis of Payments and Products
"""

df = df_deals.copy()

for col in ['Product', 'Payment Type', 'Stage']:
    df[col] = df[col].astype(str).str.strip().fillna('Unknown')

df = df[
    (df['Product'] != 'Unknown') &
    (df['Payment Type'] != 'Unknown') &
    (df['Stage'] != 'Unknown')
].copy()

agg = (
    df.groupby(['Product', 'Payment Type', 'Stage'])
    .size()
    .reset_index(name='count')
)

labels = (
    list(agg['Product'].unique()) +
    list(agg['Payment Type'].unique()) +
    list(agg['Stage'].unique())
)
label_index = {label: i for i, label in enumerate(labels)}

colors = get_my_palette(as_dict=True)
stage_colors = {
    'payment done': colors["Lime Green"][3],
    'in progress': colors["Yellowsoft"][2],
    'lost': colors["Tomato"][2],
    'call delayed': colors["Lavender"][1],
    'waiting for payment':  colors["Cornflower"][1],
    'other': colors["Neutral"][2]
}

sources, targets, values, colors_links = [], [], [], []

group_pp = (
    agg.groupby(['Product', 'Payment Type', 'Stage'])['count']
    .sum()
    .reset_index()
)
for _, row in group_pp.iterrows():
    sources.append(label_index[row['Product']])
    targets.append(label_index[row['Payment Type']])
    values.append(row['count'])

    stage_name = row['Stage'].strip().lower()
    color = stage_colors.get(stage_name, stage_colors['other'])
    colors_links.append(color)

for _, row in agg.iterrows():
    sources.append(label_index[row['Payment Type']])
    targets.append(label_index[row['Stage']])
    values.append(row['count'])

    stage_name = row['Stage'].strip().lower()
    color = stage_colors.get(stage_name, stage_colors['other'])
    colors_links.append(color)

fig = go.Figure(data=[go.Sankey(
    arrangement='snap',
    node=dict(
        pad=20,
        thickness=25,
        line=dict(color='white', width=1),
        label=labels,
        color=[colors['Lavender'][3], colors['Cornflower'][3], colors['Tomato'][3],
               colors['Lime Green'][3], colors['Yellowsoft'][3]] * (len(labels)//5 + 1)
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=colors_links,
        hovertemplate=(
            'From: %{source.label}<br>'
            'To: %{target.label}<br>'
            'Deals: %{value}<extra></extra>'
        )
    )
)])

fig.update_layout(
    title_text='Deal Flow: Product → Payment Type → Stage (colored by final Stage)',
    font=dict(size=12),
    width=1200,
    height=650,
    margin=dict(t=70, l=50, r=50, b=40),
    template='plotly_white'
)

fig.show()

"""Across all program directions, most leads successfully progress into the **Recurring Payments stage.** This means the funnel is working well up to the point of commitment.
However, from there, the largest flow goes directly into the **Lost stage** — this is the **biggest conversion** bottleneck.

A smaller share moves into **Payment Done**, while noticeable volumes get stuck in Call Delayed and Waiting for Payment.
These two stages suggest:

delays in communication,

unclear payment steps,

or lack of structured follow-ups.

**The Digital Marketing** track has the highest volume and also the highest loss rate, indicating scale without sufficient lead nurturing.
**UX/UI and Web Developer** show similar patterns, though on a smaller scale.
"""

df = df_deals.copy()

df['Payment Type'] = df['Payment Type'].astype(str).str.strip().fillna('Unknown')
df['Stage'] = df['Stage'].astype(str).str.strip().str.lower()

df['is_success'] = (df['Stage'] == 'payment done').astype(int)

df_filtered = df[
    (df['Product'] != 'Unknown') &
    (df['Education Type'] != 'Unknown') &
    (df['Payment Type'] != 'Unknown')
].copy()

df_filtered['Created Time'] = pd.to_datetime(df_filtered['Created Time'], errors='coerce')
df_filtered['Deal Created Month'] = df_filtered['Created Time'].dt.to_period('M').dt.to_timestamp()

agg = df_filtered.groupby(['Deal Created Month', 'Product']).agg(
    deals_count=('Id', 'count'),
    success_count=('is_success', 'sum')
).reset_index()

agg['conversion'] = (agg['success_count'] / agg['deals_count'] * 100).fillna(0)

colors = get_my_palette(as_dict=True)
base_color = colors["Cornflower"][3]
success_color = colors["Lime Green"][3]
trend_color = colors["Tomato"][3]

for product in agg['Product'].unique():
    dfp = agg[agg['Product'] == product]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=dfp['Deal Created Month'],
        y=dfp['deals_count'],
        name='All Deals',
        marker_color=base_color,
        opacity=0.5,
        text=dfp['deals_count'],
        textposition='outside',
        hovertemplate="Month: %{x|%b %Y}<br>Deals: %{y}<extra></extra>"
    ))

    fig.add_trace(go.Bar(
        x=dfp['Deal Created Month'],
        y=dfp['success_count'],
        name='Payment Done',
        marker_color=success_color,
        opacity=0.9,
        text=dfp['success_count'],
        textposition='outside',
        hovertemplate="Month: %{x|%b %Y}<br>Payment Done: %{y}<extra></extra>"
    ))

    fig.add_trace(go.Scatter(
        x=dfp['Deal Created Month'],
        y=dfp['conversion'],
        mode='lines',
        name='Conversion %',
        yaxis='y2',
        line=dict(color=trend_color, width=2.5, dash='dot'),
        marker=dict(size=6, color=trend_color),
        hovertemplate='Month: %{x|%b %Y}<br>Conversion: %{y:.1f}%<extra></extra>'
    ))

    fig.update_layout(
        title=f'{product}: Deals, Payment Done and Conversion by Creation Month',
        title_x=0.5,
        title_font=dict(size=16),
        barmode='overlay',
        template='plotly_white',
        width=950,
        height=500,
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5,
            font=dict(size=9)
        ),
        margin=dict(l=60, r=80, t=70, b=50),
        xaxis=dict(
            title='Month (Created)',
            tickangle=-45,
            tickformat='%b %Y',
            tickfont=dict(size=9),
            showgrid=True
        ),
        yaxis=dict(
            title='Number of Deals',
            titlefont=dict(color=base_color),
            tickfont=dict(color=base_color),
            showgrid=True
        ),
        yaxis2=dict(
            title="Conversion (%)",
            overlaying='y',
            side='right',
            titlefont=dict(color=trend_color),
            tickfont=dict(color=trend_color),
            showgrid=False
        )
    )

    fig.show()

"""**Digital Marketing**

*   Deal volume peaked from September to January, then declined.
*   Payment Done remains relatively stable, but conversion rate dropped (from ~35% to ~15%).
*   This suggests lead quality has decreased even though traffic volume stayed high.

**Conclusion:** Improve audience targeting and strengthen nurturing follow-up to restore conversion efficiency.

**UX/UI Design**

*   Deal volume is steady and gradually increasing.
*   Conversion rate remains consistently high (20–30%) with minor seasonal fluctuations.
*   The funnel is more mature—leads are coming in with clearer intent.

**Conclusion:** This direction is performing well and can be scaled by increasing budget and expanding campaigns.

**Web Developer**

*   Low volumes initially, then growth from February through April.
*   Conversion is volatile (10–40%) and strongly influenced by offer framing and messaging.
*   The audience here is more selective and reacts to credibility and clarity of value.

**Conclusion:** Test alternative messaging—portfolio proof, learning outcomes, job support, project-based training—to stabilize conversion.
"""

df = df_deals.copy()

df['Payment Type'] = df['Payment Type'].astype(str).str.strip().fillna('Unknown')
df['Stage'] = df['Stage'].astype(str).str.strip().str.lower()

df['is_success'] = (df['Stage'] == 'payment done').astype(int)

df_filtered = df[
    (df['Education Type'] != 'Unknown') &
    (df['Product'] != 'Unknown') &
    (df['Payment Type'] != 'Unknown')
].copy()

df_filtered['Created Time'] = pd.to_datetime(df_filtered['Created Time'], errors='coerce')
df_filtered['Deal Created Month'] = df_filtered['Created Time'].dt.to_period('M').dt.to_timestamp()

agg = df_filtered.groupby(['Deal Created Month', 'Education Type']).agg(
    deals_count=('Id', 'count'),
    success_count=('is_success', 'sum')
).reset_index()

agg['conversion'] = (agg['success_count'] / agg['deals_count'] * 100).fillna(0)

colors = get_my_palette(as_dict=True)
base_color = colors["Cornflower"][3]
success_color = colors["Lime Green"][3]
trend_color = colors["Tomato"][3]

for edu_type in agg['Education Type'].unique():
    df_edu = agg[agg['Education Type'] == edu_type]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=df_edu['Deal Created Month'],
        y=df_edu['deals_count'],
        name='All Deals',
        marker_color=base_color,
        opacity=0.5,
        text=dfp['deals_count'],
        textposition='outside',
        hovertemplate="Month: %{x|%b %Y}<br>Deals: %{y}<extra></extra>"
    ))

    fig.add_trace(go.Bar(
        x=df_edu['Deal Created Month'],
        y=df_edu['success_count'],
        name='Payment Done',
        marker_color=success_color,
        opacity=0.9,
        text=dfp['success_count'],
        textposition='outside',
        hovertemplate="Month: %{x|%b %Y}<br>Payment Done: %{y}<extra></extra>"
    ))

    fig.add_trace(go.Scatter(
        x=df_edu['Deal Created Month'],
        y=df_edu['conversion'],
        mode='lines',
        name='Conversion %',
        yaxis='y2',
        line=dict(color=trend_color, width=2.5, dash='dot'),
        marker=dict(size=6, color=trend_color),
        hovertemplate="Month: %{x|%b %Y}<br>Conversion: %{y:.1f}%<extra></extra>"
    ))

    fig.update_layout(
        title=f"{edu_type}: Deals, Payment Done and Conversion",
        title_x=0.5,
        title_font=dict(size=16, family="Arial"),
        barmode='overlay',
        template='plotly_white',
        width=950,
        height=500,
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='center',
            x=0.5,
            font=dict(size=9)
        ),
        margin=dict(l=60, r=80, t=70, b=50),
        xaxis=dict(
            title="Month (Created)",
            tickangle=-45,
            tickformat="%b %Y",
            tickfont=dict(size=9),
            showgrid=True
        ),
        yaxis=dict(
            title="Number of Deals",
            titlefont=dict(color=base_color),
            tickfont=dict(color=base_color),
            showgrid=True
        ),
        yaxis2=dict(
            title="Conversion (%)",
            overlaying='y',
            side='right',
            titlefont=dict(color=trend_color),
            tickfont=dict(color=trend_color),
            showgrid=False
        )
    )

    fig.show()

"""**Morning** education consistently drive much higher deal volume (**200–380 deals per month**) compared to **evening** education (**20–50 deals per month**). This makes morning the main contributor to lead flow.

However, evening education show **higher conversion rates** (often 35–55%), while morning conversion rates are lower (mostly 15–25%).
This suggests that evening leads are more qualified, possibly due to more active intent or better message relevance during this time.

In both cohorts, conversion drops in the most recent months, indicating either lower lead quality, seasonality, or less effective follow-up.
"""

df = df_deals.copy()

for col in ['Source', 'Product', 'Stage']:
    df[col] = df[col].astype(str).str.strip().fillna('Unknown')

df = df[
    (df['Source'] != 'Unknown') &
    (df['Product'] != 'Unknown') &
    (df['Stage'] != 'Unknown')
].copy()

agg = (
    df.groupby(['Source', 'Product', 'Stage'])
    .size()
    .reset_index(name='count')
)

labels = (
    list(agg['Source'].unique()) +
    list(agg['Product'].unique()) +
    list(agg['Stage'].unique())
)
label_index = {label: i for i, label in enumerate(labels)}

colors = get_my_palette(as_dict=True)
stage_colors = {
    'payment done': colors['Lime Green'][3],
    'in progress': colors['Yellowsoft'][2],
    'lost': colors['Tomato'][2],
    'call delayed': colors['Lavender'][1],
    'waiting for payment':  colors['Cornflower'][2],
    'other': colors['Neutral'][2]
}

sources, targets, values, colors_links = [], [], [], []

group_sp = (
    agg.groupby(['Source', 'Product', 'Stage'])['count']
    .sum()
    .reset_index()
)
for _, row in group_sp.iterrows():
    sources.append(label_index[row['Source']])
    targets.append(label_index[row['Product']])
    values.append(row['count'])

    stage_name = row['Stage'].strip().lower()
    color = stage_colors.get(stage_name, stage_colors['other'])
    colors_links.append(color)

for _, row in agg.iterrows():
    sources.append(label_index[row['Product']])
    targets.append(label_index[row['Stage']])
    values.append(row['count'])

    stage_name = row['Stage'].strip().lower()
    color = stage_colors.get(stage_name, stage_colors['other'])
    colors_links.append(color)

fig = go.Figure(data=[go.Sankey(
    arrangement='snap',
    node=dict(
        pad=20,
        thickness=25,
        line=dict(color='white', width=1),
        label=labels,
        color=[colors['Lavender'][3], colors['Cornflower'][3], colors['Tomato'][3],
               colors['Lime Green'][3], colors['Yellowsoft'][3]] * (len(labels)//5 + 1)
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=colors_links,
        hovertemplate=(
            'From: %{source.label}<br>'
            'To: %{target.label}<br>'
            'Deals: %{value}<extra></extra>'
        )
    )
)])

fig.update_layout(
    title_text='Deal Flow: Source → Product → Stage (colored by final Stage)',
    font=dict(size=12),
    width=1200,
    height=700,
    margin=dict(t=70, l=50, r=50, b=40),
    template='plotly_white'
)

fig.show()

"""This Sankey chart shows how deals flow from **Source → Product → Final Stage.**

**Facebook Ads and Google Ads** provide the largest volume of leads, but a large portion ultimately ends in Lost — meaning these channels generate quantity, but the leads require better qualification and follow-up.

**Organic and SMM** channels send fewer leads overall, but a much larger share reaches “Payment Done.” These channels deliver higher-quality and more motivated leads.

**The Digital Marketing** program receives the highest lead volume, and also has the highest loss rate, suggesting capacity issues, sales pressure, or weaker initial lead intent.

**UX/UI Design and Web Developer** programs show more efficient conversion flows, especially from Organic and SMM sources.

A significant number of leads get stuck in “Call Delayed” and “Waiting for Payment”, indicating pipeline bottlenecks in communication and payment processing.
"""

agg = (
    df_filtered.groupby(['Source', 'Product'])
    .agg(total=('Id','count'),
         success=('is_success','sum'))
    .reset_index()
)
agg['success_rate'] = agg['success'] / agg['total']

colors = get_my_palette(as_dict=True)
fig = px.scatter(
    agg,
    x='Source',
    y='Product',
    size='total',
    color='success_rate',
    color_continuous_scale=[
        [0.0, colors["Tomato"][3]],
        [0.5, colors["Yellowsoft"][3]],
        [1.0, colors["Lime Green"][3]]
    ],
    title="Source vs Product — Success Rate Bubble Matrix",
    size_max=40
)

fig.update_layout(
    template='plotly_white',
    height=600,
    xaxis=dict(tickangle=-30),
    coloraxis_colorbar=dict(title="Success Rate"),
)
fig.show()

"""**Source vs Product – Success Rate Insights**

**Facebook Ads and Google Ads** generate the largest lead volumes across all products (biggest bubbles), but their success rates are moderate. This means they bring scale, but require strong qualification and follow-up to convert.

**Organic** consistently shows higher success rates (greener bubbles), especially for Digital Marketing and UX/UI Design — indicating high-intent leads who already trust the brand.

**SMM and Telegram Posts** provide balanced performance: good lead volume and stable mid-level success rates. These channels are cost-efficient and reliable.

**Webinar** shows high success rates for Digital Marketing, despite lower volume — a strong quality over quantity channel.

**Bloggers, CRM, TikTok Ads, Youtube Ads** produce smaller volumes and lower conversion, making them secondary or experimental channels.
"""

df = df_deals.copy()

for col in ['Product', 'Payment Type', 'Stage']:
    df[col] = df[col].astype(str).str.strip().fillna('Unknown')

df = df[
    (df['Product'] != 'Unknown') &
    (df['Payment Type'] != 'Unknown') &
    (df['Stage'] != 'Unknown')
].copy()

df['is_success'] = df['Stage'].str.lower().eq('payment done').astype(int)

if 'Month' not in df.columns:
    df['Month'] = pd.to_datetime(df['Closing Date'], errors='coerce').dt.to_period('M').dt.to_timestamp()

agg = (
    df.groupby('Payment Type')
    .agg(
        total_deals=('Id', 'count'),
        success_count=('is_success', 'sum')
    )
    .reset_index()
)

agg['success_rate'] = (agg['success_count'] / agg['total_deals']).fillna(0)

colors_dict = get_my_palette(as_dict=True)
colors = [
    colors_dict["Lime Green"][2],
    colors_dict["Cornflower"][3],
    colors_dict["Tomato"][2],
    colors_dict["Lavender"][1],
    colors_dict["Lime Green"][0],
]

fig = px.pie(
    agg,
    names='Payment Type',
    values='success_rate',
    color='Payment Type',
    color_discrete_sequence=colors,
    hole=0.4,
    title='Success Rate by Payment Type'
)

fig.update_traces(
    textinfo='label+percent',
    pull=[0.05 if x == agg['success_rate'].max() else 0 for x in agg['success_rate']],
    textfont_size=14
)

fig.update_layout(
    template='plotly_white',
    height=500,
    margin=dict(l=40, r=40, t=60, b=40),
    showlegend=True,
    font=dict(size=12, color='#333')
)

fig.show()

"""The majority of customers (**≈ 67%**) make a **one-time payment**, meaning most deals are closed in a straightforward single-payment model.

About **23%** of customers pay through **recurring** installments, which indicates a solid share of long-term retention and subscription-style revenue.

**Reservations **(**≈ 7%**) represent leads who expressed commitment but haven’t fully paid yet — this group is important to follow up and convert.

A small fraction (**≈ 2%)** resulted in **no payment at all**, indicating very low payment failure or churn after the decision.
"""

fig = px.parallel_categories(
    df,
    dimensions=['Education Type', 'Payment Type', 'Stage'],
    color=df['Stage'].astype('category').cat.codes,
    color_continuous_scale=colors,
    title='Parallel Categories: Education → Payment → Stage'
)
fig.update_layout(height=600)
fig.show()

"""**Education → Payment → Stage Flow Analysis**

**Morning** learners make up the largest share of deals.

Within this group, most payments are “**Recurring Payments**”, but a significant portion still ends in “Lost”, indicating drop-off during later stages.

**Evening** learners convert less frequently, and their payment behavior is more often **One Payment or No Payment**, suggesting lower engagement or weaker follow-up processes.

**Unknown** segment is small and inconsistent — likely low-quality or unclassified leads.
"""

agg = (
    df_filtered
    .groupby(['Product', 'Education Type', 'Stage'])
    .size()
    .reset_index(name='count')
)

cornflower = get_my_palette(group='Cornflower')
yellow = get_my_palette(group='Yellowsoft')
lavender = get_my_palette(group='Lavender')
tomato = get_my_palette(group='Tomato')
lime = get_my_palette(group='Lime Green')
neutral = get_my_palette(group='Neutral')

stage_colors = {
    'payment done': lime[3],
    'lost': tomato[2],
    'call delayed': yellow[2],
    'test sent': lavender[3],
    'waiting for payment': lime[1],
    'qualificated': neutral[2],
}

education_colors = {
    'Morning': cornflower[2],
    'Evening': lavender[2],
    'Unknown': yellow[3],
}

product_color = neutral[2]

color_map = {**stage_colors, **education_colors}

fig = px.treemap(
    agg,
    path=['Product', 'Education Type', 'Stage'],
    values='count',
    color='Stage',
    color_discrete_map=color_map,
    title='Deals Breakdown by Product → Education Type → Stage'
)

colors = list(fig.data[0]['marker']['colors'])
labels = fig.data[0]['labels']
products = agg['Product'].unique()
education_types = agg['Education Type'].unique()

for i, label in enumerate(labels):
    if label in products:
        colors[i] = product_color
    elif label in education_types:
        colors[i] = education_colors.get(label, cornflower[2])

fig.data[0]['marker']['colors'] = tuple(colors)

fig.update_traces(
    texttemplate='<b>%{label}</b><br>%{value:,} deals<br>%{percentParent:.1%}',
    hovertemplate='<b>%{label}</b><br>%{value:,} deals<br>%{percentParent:.1%} of parent'
)
fig.update_layout(
    template='plotly_white',
    font=dict(size=13),
    title_font=dict(size=18, family='Arial', color='#333'),
    margin=dict(t=70, l=10, r=10, b=10),
    paper_bgcolor='rgba(255,255,255,0)',
    plot_bgcolor='rgba(255,255,255,0)',
    height=700
)

save_plot('treemap_product_education_stage_colored', subfolder='notebooks')
fig.show()

"""**Treemap Analysis: Product → Education Type → Stage**

**Morning leads** dominate across all products — most deals are created in the morning.
However, loss rates are also highest in the morning:

Digital Marketing (Morning): **~54% lost**

UX/UI (Morning): **~57% lost**

Web Developer (Morning): **~46% lost**

This indicates large volume but lower lead qualification in the morning.

**Evening leads** are fewer, but conversion is higher:

**Payment Done** share is noticeably stronger in the Evening, especially in Digital Marketing.

Evening leads likely show higher intent (warmer audience / self-directed search behavior).

# GeoAnalysis

### 1. Deals for city
"""

city_counts = (
    df_deals.groupby(['City', 'Latitude', 'Longitude'], as_index=False)
    .size()
    .rename(columns={'size': 'Deal Count'}))

df_heat = city_counts.dropna(subset=['Latitude', 'Longitude']).copy()

red_scale = get_my_palette(group='Tomato')[-1]
blue_scale = get_my_palette(group='Cornflower')[-1]
lavender_scale = get_my_palette(group='Lavender')[2]

m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='cartodb positron')

marker_cluster = MarkerCluster(
    name='Cities by deals',
    icon_create_function=f'''
    function (cluster) {{
        var count = cluster.getChildCount();
        var color = (count > 100) ? '{red_scale}' :
                    (count > 20)  ? '{blue_scale}' :
                                    '{lavender_scale}';
        return new L.DivIcon({{
            html: '<div style="background:' + color + '; border-radius:50%; ' +
                  'width:45px; height:45px; display:flex; align-items:center; justify-content:center; ' +
                  'color:white; font-weight:bold; font-size:13px; border:2px solid rgba(255,255,255,0.8);">' +
                  count + '</div>',
            className: 'marker-cluster',
            iconSize: new L.Point(40, 40)
        }});
    }}
    '''
).add_to(m)

for _, row in df_heat.iterrows():
    popup_html = f'''
    <div style="font-family:Arial; font-size:13px;">
        <b>{row['City']}</b><br>Deals: {int(row['Deal Count'])}
    </div>
    '''
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=5,
        color='#9AC400',
        fill=True,
        fill_opacity=0.9,
        popup=popup_html
    ).add_to(marker_cluster)

legend_html = f'''
<div style="
    position: fixed;
    top: 50px; left: 50px; width: 220px; height: 120px;
    border:2px solid #ccc; z-index:9999; font-size:13px;
    background:white; padding: 10px; border-radius:8px;">
<b>City Cluster Scale</b><br>
<span style="color:#9AC400;">&#9679;</span> One city (1)<br>
<span style="color:{lavender_scale};">&#9679;</span> Local clusters (2–20)<br>
<span style="color:{blue_scale};">&#9679;</span> Regional centers (20–100)<br>
<span style="color:{red_scale};">&#9679;</span> Major economic hubs (100+)
</div>
'''
m.get_root().html.add_child(folium.Element(legend_html))

title_html = '''
<h3 align='center' style='font-size:20px; margin-top:10px;'>
    <b>Hierarchical Cluster Visualization of City Deals</b>
</h3>
'''
m.get_root().html.add_child(folium.Element(title_html))

m.save('cluster_levels_red_blue_lavender.html')
m

"""The deal market is concentrated in central and southern Germany, where key economic centers are located. Other regions show limited activity and fragmented local clusters.

### 2. Deutsch level in each city
"""

df_map = (
    df_deals.groupby(['City', 'German Level', 'Latitude', 'Longitude'])
    .size()
    .reset_index(name='Deal Count')
)

color_groups = get_my_palette(as_dict=True)
colormap = {
    'A0': color_groups['Neutral'][3],
    'A1': color_groups['Lavender'][4],
    'A2': color_groups['Tomato'][4],
    'B1': color_groups['Lime Green'][4],
    'B2': color_groups['Cornflower'][3],
    'C1': color_groups['Yellowsoft'][4],
    'C2': color_groups['Lime Green'][2],
    'Unknown': color_groups['Neutral'][4],
}

m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='cartodb positron')
cluster = MarkerCluster().add_to(m)

for _, row in df_map.iterrows():
    color = colormap.get(row['German Level'], '#CCCCCC')
    popup_html = f'''
    <b>{row['City']}</b><br>
    German Level: {row['German Level']}<br>
    Deals: {row['Deal Count']}
    '''
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=max(4, min(12, row['Deal Count'] / 3)),
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.85,
        popup=popup_html
    ).add_to(cluster)

legend_html = f'''
<div style='
position: fixed;
top: 50px; left: 50px; width: 160px;
border:2px solid #ccc; z-index:9999; background:white;
padding: 10px; border-radius:8px; font-size:13px;'>
<b>German Language Levels</b><br>
{''.join([f"<span style='color:{colormap[lvl]};'>&#9679;</span> {lvl}<br>" for lvl in colormap.keys()])}
</div>
'''
m.get_root().html.add_child(folium.Element(legend_html))

title_html = '''
<h3 align='center' style='font-size:20px; margin-top:10px;'>
    <b>Impact of German Language Level on Deal Activity</b>
</h3>
'''
m.get_root().html.add_child(folium.Element(title_html))

m.save('german_level_map.html')
m

"""The highest concentration of deals is observed in western and southern Germany: North Rhine-Westphalia, Hesse, Bavaria, and Baden-Württemberg.

In the north (Hamburg, Schleswig-Holstein) and the east (Mecklenburg, Brandenburg), A2–B1 levels are more common, suggesting moderate language proficiency and lower business activity.

### 3. Deutsch level with successful deal
"""

df_success = df_deals[df_deals['Stage'] == 'Payment Done']

df_map = (
    df_success.groupby(['City', 'German Level', 'Latitude', 'Longitude'])
    .size()
    .reset_index(name='Deal Count')
)

color_groups = get_my_palette(as_dict=True)
colormap = {
    'A0': color_groups['Neutral'][3],
    'A1': color_groups['Lavender'][4],
    'A2': color_groups['Tomato'][4],
    'B1': color_groups['Lime Green'][4],
    'B2': color_groups['Cornflower'][3],
    'C1': color_groups['Yellowsoft'][4],
    'C2': color_groups['Lime Green'][2],
}

m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='cartodb positron')
cluster = MarkerCluster().add_to(m)

for _, row in df_map.iterrows():
    color = colormap.get(row['German Level'], '#CCCCCC')
    popup_html = f'''
    <b>{row['City']}</b><br>
    German Level: {row['German Level']}<br>
    Successful Deals: {row['Deal Count']}
    '''
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=max(4, min(12, row['Deal Count'] / 3)),
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.85,
        popup=popup_html
    ).add_to(cluster)

legend_html = f'''
<div style='
position: fixed;
top: 50px; left: 50px; width: 160px;
border:2px solid #ccc; z-index:9999; background:white;
padding: 10px; border-radius:8px; font-size:13px;'>
<b>German Language Levels</b><br>
{''.join([f"<span style='color:{colormap[lvl]};'>&#9679;</span> {lvl}<br>" for lvl in colormap.keys()])}
</div>
'''
m.get_root().html.add_child(folium.Element(legend_html))

title_html = '''
<h3 align='center' style='font-size:20px; margin-top:10px;'>
    <b>Impact of German Language Level on Successful Deal Activity</b>
</h3>
'''
m.get_root().html.add_child(folium.Element(title_html))

m.save('german_level_success_map.html')
m

"""The core of successful deals is again concentrated in central and southern Germany (**North Rhine-Westphalia, Bavaria, Baden-Württemberg)**.

In the northern and eastern regions, the number of successful deals is significantly lower, while the share of participants with A1–A2 language levels remains high — which correlates with reduced deal success.

Interestingly, in major cities (e.g., **Munich**), successful deals are made across different language proficiency levels, indicating a more advanced communication and support infrastructure.

### 4. Deutsch level without Unknown
"""

df_grouped = (
    df_deals[df_deals['German Level'].notna()]
    .groupby(['City', 'German Level', 'Latitude', 'Longitude'])
    .size()
    .reset_index(name='Deal Count')
)

color_groups = get_my_palette(as_dict=True)
colormap = {
    'A0': color_groups['Neutral'][3],
    'A1': color_groups['Lavender'][4],
    'A2': color_groups['Tomato'][4],
    'B1': color_groups['Lime Green'][4],
    'B2': color_groups['Cornflower'][3],
    'C1': color_groups['Yellowsoft'][4],
    'C2': color_groups['Lime Green'][2],
}

df_grouped = df_grouped[df_grouped['German Level'].isin(colormap.keys())]

m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='cartodb positron')

for city, group in df_grouped.groupby('City'):
    lat, lon = group['Latitude'].iloc[0], group['Longitude'].iloc[0]
    total_deals = int(group['Deal Count'].sum())

    if len(group) == 1:
        lvl = group['German Level'].iloc[0]
        color = colormap.get(lvl, '#999999')
        deals = int(group['Deal Count'].iloc[0])
        popup_html = f'''
        <b>{city}</b><br>
        Level: {lvl}<br>
        Deals: {deals}
        '''
        folium.CircleMarker(
            location=[lat, lon],
            radius=max(6, min(14, deals * 1.2)),
            color=color,
            fill=True,
            fill_color=color,
            fill_opacity=0.85,
            popup=popup_html,
            tooltip=f'{city} — {lvl} ({deals})'
        ).add_to(m)

    else:
        levels = group['German Level'].tolist()
        counts = group['Deal Count'].tolist()
        colors = [colormap.get(l, '#999999') for l in levels]

        fig, ax = plt.subplots(figsize=(2.4, 2.4))
        wedges, texts, autotexts = ax.pie(
            counts,
            labels=None,
            colors=colors,
            startangle=90,
            autopct=lambda p: f'{int(round(p * sum(counts) / 100))}' if p > 0 else '',
            pctdistance=0.75,
            textprops={'fontsize': 8, 'weight': 'bold', 'color': 'black'}
        )
        ax.axis('equal')

        centre_circle = plt.Circle((0, 0), 0.45, fc='white')
        fig.gca().add_artist(centre_circle)
        ax.text(0, 0, str(total_deals), ha='center', va='center',
                fontsize=11, fontweight='bold', color='black')

        buf = BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight', transparent=True)
        plt.close(fig)
        data = base64.b64encode(buf.getvalue()).decode('utf-8')

        legend_html = '<div style="font-size:11px; text-align:center; margin-top:5px;">'
        for lvl, cnt, clr in zip(levels, counts, colors):
            legend_html += f'<span style="color:{clr};">&#9679;</span> {lvl} ({cnt}) &nbsp;'
        legend_html += '</div>'

        popup_html = f'''
        <div style='text-align:center; font-family:Arial; font-size:13px;'>
            <b>{city}</b><br>
            <img src='data:image/png;base64,{data}' width="160"><br>
            {legend_html}
        </div>
        '''

        folium.CircleMarker(
            location=[lat, lon],
            radius=max(6, min(14, total_deals * 1.2)),
            color='#999999',
            fill=True,
            fill_color='#999999',
            fill_opacity=0.75,
            popup=popup_html,
            tooltip=f'{city} — Multiple Levels ({total_deals})'
        ).add_to(m)

legend_html = f'''
<div style='
position: fixed;
top: 50px; left: 50px; width: 180px;
border:2px solid #ccc; z-index:9999; background:white;
padding: 10px; border-radius:8px; font-size:13px;'>
<b>German Language Levels</b><br>
{''.join([f'<span style="color:{colormap[lvl]};">&#9679;</span> {lvl}<br>' for lvl in colormap.keys()])}
<span style='color:#999999;'>&#9679;</span> Multiple Levels (Pie)
</div>
'''
m.get_root().html.add_child(folium.Element(legend_html))

title_html = '''
<h3 align='center' style='font-size:20px; margin-top:10px;'>
<b>Deal Activity by German Language Level Across Cities</b>
</h3>
'''
m.get_root().html.add_child(folium.Element(title_html))

m.save('german_language_map.html')
m

"""The cities of Munich, Frankfurt, Stuttgart, and Hamburg show balanced language-level distributions, indicating strong cultural and professional integration.

The high concentration of multi-level deals in large urban centers suggests linguistic flexibility and an open market structure. The greater the linguistic diversity, the broader the deal geography and the higher the overall deal volume.

### 5. Deutsch level without Unknown only successful deals
"""

df_success = df_deals[
    (df_deals['Stage'].astype(str).str.strip().str.lower() == 'payment done') &
    (df_deals['German Level'].notna()) &
    (df_deals['City'].notna())
]

df_grouped = (
    df_success
    .groupby(['City', 'German Level', 'Latitude', 'Longitude'])
    .size()
    .reset_index(name='Deal Count')
)

color_groups = get_my_palette(as_dict=True)
colormap = {
    'A0': color_groups['Neutral'][3],
    'A1': color_groups['Lavender'][4],
    'A2': color_groups['Tomato'][4],
    'B1': color_groups['Lime Green'][4],
    'B2': color_groups['Cornflower'][3],
    'C1': color_groups['Yellowsoft'][4],
    'C2': color_groups['Lime Green'][2],
}

df_grouped = df_grouped[df_grouped['German Level'].isin(colormap.keys())]

m = folium.Map(location=[51.1657, 10.4515], zoom_start=6, tiles='cartodb positron')

for city, group in df_grouped.groupby('City'):
    lat, lon = group['Latitude'].iloc[0], group['Longitude'].iloc[0]
    total_deals = int(group['Deal Count'].sum())

    if len(group) == 1:
        lvl = group['German Level'].iloc[0]
        color = colormap.get(lvl, '#999999')
        deals = int(group['Deal Count'].iloc[0])
        popup_html = f'''
        <b>{city}</b><br>
        Level: {lvl}<br>
        Successful Deals: {deals}
        '''
        folium.CircleMarker(
            location=[lat, lon],
            radius=max(6, min(14, deals * 1.2)),
            color=color,
            fill=True,
            fill_color=color,
            fill_opacity=0.85,
            popup=popup_html,
            tooltip=f'{city} — {lvl} ({deals})'
        ).add_to(m)

    else:
        levels = group['German Level'].tolist()
        counts = group['Deal Count'].tolist()
        colors = [colormap.get(l, '#999999') for l in levels]

        fig, ax = plt.subplots(figsize=(2.4, 2.4))
        ax.pie(
            counts,
            colors=colors,
            startangle=90,
            autopct=lambda p: f'{int(round(p * sum(counts) / 100))}' if p > 0 else '',
            pctdistance=0.75,
            textprops={'fontsize': 8, 'weight': 'bold', 'color': 'black'}
        )
        ax.axis('equal')

        centre_circle = plt.Circle((0, 0), 0.45, fc='white')
        fig.gca().add_artist(centre_circle)
        ax.text(0, 0, str(total_deals), ha='center', va='center',
                fontsize=11, fontweight='bold', color='black')

        buf = BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight', transparent=True)
        plt.close(fig)
        data = base64.b64encode(buf.getvalue()).decode('utf-8')

        legend_html = '<div style="font-size:11px; text-align:center; margin-top:5px;">'
        for lvl, cnt, clr in zip(levels, counts, colors):
            legend_html += f'<span style="color:{clr};">&#9679;</span> {lvl} ({cnt}) &nbsp;'
        legend_html += '</div>'

        popup_html = f'''
        <div style='text-align:center; font-family:Arial; font-size:13px;'>
            <b>{city}</b><br>
            <img src='data:image/png;base64,{data}' width="160"><br>
            {legend_html}
        </div>
        '''

        folium.CircleMarker(
            location=[lat, lon],
            radius=max(6, min(14, total_deals * 1.2)),
            color='#999999',
            fill=True,
            fill_color='#999999',
            fill_opacity=0.75,
            popup=popup_html,
            tooltip=f'{city} — Multiple Levels ({total_deals})'
        ).add_to(m)

legend_html = f'''
<div style='
position: fixed;
top: 50px; left: 50px; width: 180px;
border:2px solid #ccc; z-index:9999; background:white;
padding: 10px; border-radius:8px; font-size:13px;'>
<b>German Language Levels</b><br>
{''.join([f'<span style="color:{colormap[lvl]};">&#9679;</span> {lvl}<br>' for lvl in colormap.keys()])}
<span style='color:#999999;'>&#9679;</span> Multiple Levels (Pie)
</div>
'''
m.get_root().html.add_child(folium.Element(legend_html))

title_html = '''
<h3 align='center' style='font-size:20px; margin-top:10px;'>
<b>Successful Deal Activity by German Language Level Across Cities</b>
</h3>
'''
m.get_root().html.add_child(folium.Element(title_html))

m.save('german_language_success_map.html')
m

"""The highest number of successful deals is observed in western and southern Germany (Frankfurt, Stuttgart, Munich, Nuremberg).

Deals in northern and eastern regions also occur, but mostly among participants at the B1 level, and the success rate there is noticeably lower.

Multi-level hubs (such as Frankfurt and Munich) demonstrate strong performance even with a mix of language proficiency levels — indicating a well-developed communication and support infrastructure.

**Conclusion:**
There is a clear positive correlation between German language proficiency and deal success. Higher language levels significantly increase the likelihood of closing a deal, while cities with diverse language environments show better adaptation and communication across the market.
"""
